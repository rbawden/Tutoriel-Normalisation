{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rbawden/Tutoriel-Normalisation/blob/main/Tutoriel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorations sur la normalisation du français moderne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup de l'environnement, téléchargement des fichiers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installer les paquets python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install fairseq@git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52 \n",
    "!pip install sentencepiece sacrebleu hydra-core omegaconf==2.0.5 gdown==4.2.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Télécharger les données et les modèles depuis Google Drive et stocker-les dans `data-models/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "![ -d data-models ] || gdown https://drive.google.com/drive/folders/1h-qSnPBPZFZQ_kqWIBMhkkFS-6C2b10H?usp=sharing -O data-models --folder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer des liens symboliques pour rendre les fichiers/dossiers téléchargés plus accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![ -d data ] || mkdir data; [ -d models ] || mkdir models; [ -d scripts ] || mkdir scripts\n",
    "!for file in data-models/*{src,trg,model,vocab}; do ln -sf  $PWD/$file $PWD/data/; done\n",
    "!for file in data-models/*{txt,pt}; do ln -sf $PWD/$file $PWD/models/; done\n",
    "!for file in data-models/*{py}; do ln -sf $PWD/$file $PWD/scripts/; done\n",
    "!ln -sf $PWD/models/dict.txt $PWD/models/dict.src.txt\n",
    "!ln -sf $PWD/models/dict.txt $PWD/models/dict.trg.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Préparation des données à normaliser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions pour lire le contenu d'un fichier ligne par ligne et pour les lire depuis un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "  contents = []\n",
    "  with open(filename) as fp:\n",
    "    for line in fp:\n",
    "      contents.append(line.strip())\n",
    "  return contents\n",
    "\n",
    "def write_file(list_sents, filename):\n",
    "    with open(filename, 'w') as fp:\n",
    "        for sent in list_sents:\n",
    "            fp.write(sent + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lire le contenu des données parallèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_src = read_file('data/dev.src')\n",
    "data_trg = read_file('data/dev.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser le début des textes sources (src) et cibles (trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print('src = ', data_src[i])\n",
    "    print('trg = ', data_trg[i])\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger le modèle de segmentation en sous-mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece\n",
    "spm = sentencepiece.SentencePieceProcessor(model_file='data/bpe_joint_1000.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer le modèle sur les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_src_sp = spm.encode(data_src, out_type=str)\n",
    "data_trg_sp = spm.encode(data_trg, out_type=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire les données pre-traités dans des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file([' '.join(phrase) for phrase in data_src_sp], 'data/dev.sp.src')\n",
    "write_file([' '.join(phrase) for phrase in data_trg_sp], 'data/dev.sp.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser le début de textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print('src = ', data_src_sp[i])\n",
    "    print('trg = ', data_trg_sp[i])\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définir une fonction pour détokeniser (pour plus tard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sp(list_sents):\n",
    "    return [''.join(sent).replace(' ', '').replace('▁', ' ') for sent in list_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser à quoi ressemble le texte détokenisé (Spoiler: il devrait ressembler au texte de départ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_sp(data_src_sp[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Appliquer le modèle de normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer le modèle de normalisation sur le début des données pre-traitées (les messages \"User Warning\" ne sont pas graves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head -n 10 data/dev.sp.src | fairseq-interactive models/ --source-lang src --target-lang trg --path models/lstm_norm.pt > data/dev.sp.norm.trg.10.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sortie de fairseq-interactive donne quelque chose comme ceci:\n",
    "\n",
    "```\n",
    "S-0     ▁1 .\n",
    "H-0     -0.00011481383990030736 ▁1 .\n",
    "P-0     -0.0000 -0.0003 -0.0000\n",
    "S-1     ▁1 . ▁Q V e ▁cette ▁prop ost ion , ▁qu ' vn ▁esp ace ▁est ▁v ui d é , ▁re p u gne ▁au ▁sens ▁comm un .\n",
    "H-1     -0.039981111884117126   ▁1 . ▁Q U e ▁cette ▁prop ost ion , ▁qu ' un ▁esp ace ▁est ▁v ui d é , ▁rép u gne ▁au ▁sens ▁comm un .\n",
    "P-1     -0.0000 -0.0000 -0.0043 -0.0632 -0.0006 -0.0000 -0.0001 -0.9353 -0.0001 -0.0012 -0.0000 0.0000 -0.0001 -0.0078 -0.0070 -0.0000 -0.0022 -0.1168 -0.0001 -0.0000 -0.0000 -0.0389 -0.0157 -0.0053 -0.0000 -0.0000 -0.0001 -0.0000 -0.0004 -0.0000\n",
    "S-2     ▁1 . ▁Q V e ▁tous ▁les ▁cor p s ▁ont ▁re p u gn ance ▁à ▁se ▁se p are r ▁l ' vn ▁de ▁l ' autre , ▁& ▁ad m ettre ▁du ▁v ui de ▁dans ▁leur ▁in ter u al le ;\n",
    "W-2     0.682   seconds\n",
    "H-2     -0.019450930878520012   ▁1 . ▁Q U e ▁tous ▁les ▁cor p s ▁ont ▁rép u gn ance ▁à ▁se ▁s ép are r ▁l ' un ▁de ▁l ' autre , ▁et ▁ad m ettre ▁du ▁v ui de ▁dans ▁leur ▁in ter v és le ;\n",
    "D-2     -0.019450930878520012   ▁1 . ▁Q U e ▁tous ▁les ▁cor p s ▁ont ▁rép u gn ance ▁à ▁se ▁s ép are r ▁l ' un ▁de ▁l ' autre , ▁et ▁ad m ettre ▁du ▁v ui de ▁dans ▁leur ▁in ter v és le ;\n",
    "P-2     -0.0000 -0.0001 -0.0040 -0.1684 -0.0004 -0.0000 -0.0000 -0.0000 -0.0007 -0.0000 -0.0001 -0.1220 -0.0063 -0.0002 -0.0137 -0.0000 -0.0000 -0.0002 -0.0001 -0.0248 -0.0022 -0.0003 -0.0000 -0.0000 -0.0000 -0.0000 -0.0000 -0.0000 -0.0002 -0.0001 -0.0000 -0.0000 -0.0000 -0.0000 -0.0383 -0.0173 -0.0006 -0.0000 -0.0000 -0.0000 -0.0066 -0.0016 -0.4856 -0.0007 -0.0002 -0.0000\n",
    "```\n",
    "\n",
    "Les informations intéressantes pour l'exemple `i`:\n",
    "\n",
    "- S-i: le texte source\n",
    "- W-i: la durée de la normalisation de ce texte\n",
    "- H-i: le score de l'hypothèse et l'hypothèse du modèle (c'est-à-dire la prédiction)\n",
    "- P-i: les scores de chaque sous-token produit par le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour extraire l'hypothèse de ce fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hypothesis(filename):\n",
    "    outputs = []\n",
    "    with open(filename) as fp:\n",
    "        for line in fp:\n",
    "            if 'H-' in line:\n",
    "                outputs.append(line.strip().split('\\t')[2])\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraire les hypothèses du fichier produit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = extract_hypothesis('data/dev.sp.norm.trg.10.output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-traité le texte avec la fonction précedemment définie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_postproc = decode_sp(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrire le résultat dans un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(outputs_postproc, 'data/dev.sp.norm.10.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Évaluation du résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BLEU: le métrique d'évaluation le plus fréquemment utilisé en traduction automatique\n",
    "- ChrF: CharacterF score (like BLEU but based on n-grams of characters)\n",
    "- TER: translation edit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU, CHRF, TER\n",
    "bleu = BLEU()\n",
    "bleu.corpus_score(outputs_postproc, [data_trg[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrf = CHRF()\n",
    "chrf.corpus_score(outputs_postproc, [data_trg[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ter = TER()\n",
    "ter.corpus_score(outputs_postproc, [data_trg[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une évaluation plus adaptée: la précision au niveau de chaque mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments = align.align('data/dev.sp.src', 'data/dev.sp.norm.trg', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_diff = 0\n",
    "total = 0\n",
    "for sentence in alignments:\n",
    "    for word in sentence:\n",
    "        if '>' in word:\n",
    "            num_diff += 1\n",
    "        total += 1\n",
    "print('Accuracy = ' + str(num_diff/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Quelques extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire une analyse qualitative de résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_frequent_diffs(alignments, show_n=10):\n",
    "    # TODO\n",
    "    return\n",
    "\n",
    "print_most_frequent_errors(alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire une analyse qualitative des différences entre un texte source et cible - faire cette analyse sur le jeu d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer une baseline par règles. Comme ressources supplémentaires, vous avez un lexique de mots en français contemporain et quelques fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lexicon():\n",
    "    return\n",
    "\n",
    "def similarity():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN8AweSe1ASxQbXHW5LKQ6B",
   "include_colab_link": true,
   "name": "Tutoriel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
