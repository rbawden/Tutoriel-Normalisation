{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rbawden/Tutoriel-Normalisation/blob/main/Tutoriel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorations sur la normalisation du français moderne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup de l'environnement, téléchargement des fichiers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installer les paquets python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52\n",
      "  Using cached fairseq-1.0.0a0+5a75b07-cp37-cp37m-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: tqdm in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (4.62.3)\n",
      "Requirement already satisfied: cffi in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (1.15.0)\n",
      "Requirement already satisfied: torch in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (1.10.0)\n",
      "Requirement already satisfied: cython in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (0.29.24)\n",
      "Requirement already satisfied: numpy in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (1.21.4)\n",
      "Requirement already satisfied: regex in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (2021.11.10)\n",
      "Requirement already satisfied: hydra-core<1.1 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (1.0.7)\n",
      "Requirement already satisfied: omegaconf<2.1 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (2.0.5)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (2.0.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from hydra-core<1.1->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (4.8)\n",
      "Requirement already satisfied: importlib-resources in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from hydra-core<1.1->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from omegaconf<2.1->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (4.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from omegaconf<2.1->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (6.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (0.8.9)\n",
      "Requirement already satisfied: colorama in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (0.4.4)\n",
      "Requirement already satisfied: portalocker in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (2.3.2)\n",
      "Requirement already satisfied: pycparser in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from cffi->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (2.21)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from importlib-resources->hydra-core<1.1->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (3.6.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (0.1.96)\n",
      "Requirement already satisfied: sacrebleu in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: hydra-core in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (1.0.7)\n",
      "Requirement already satisfied: omegaconf==2.0.5 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (2.0.5)\n",
      "Requirement already satisfied: gdown==4.2.0 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (4.2.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from omegaconf==2.0.5) (6.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from omegaconf==2.0.5) (4.0.0)\n",
      "Requirement already satisfied: requests[socks] in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from gdown==4.2.0) (2.26.0)\n",
      "Requirement already satisfied: filelock in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from gdown==4.2.0) (3.4.0)\n",
      "Requirement already satisfied: six in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from gdown==4.2.0) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from gdown==4.2.0) (4.62.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from gdown==4.2.0) (4.10.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu) (0.8.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu) (1.21.4)\n",
      "Requirement already satisfied: regex in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu) (2021.11.10)\n",
      "Requirement already satisfied: colorama in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu) (0.4.4)\n",
      "Requirement already satisfied: portalocker in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu) (2.3.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from hydra-core) (4.8)\n",
      "Requirement already satisfied: importlib-resources in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from hydra-core) (5.4.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from beautifulsoup4->gdown==4.2.0) (2.3.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from importlib-resources->hydra-core) (3.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from requests[socks]->gdown==4.2.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from requests[socks]->gdown==4.2.0) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from requests[socks]->gdown==4.2.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from requests[socks]->gdown==4.2.0) (1.26.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from requests[socks]->gdown==4.2.0) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install fairseq@git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52 \n",
    "!pip install sentencepiece sacrebleu hydra-core omegaconf==2.0.5 gdown==4.2.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Télécharger les données et les modèles depuis Google Drive et structures-les dans les dossiers `data/`, `models/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving folder list\n",
      "Processing file 1Rfg--VzD1S2F3BQ0O4WztUGO0KI9iaQW align.py\n",
      "Processing file 18oYa_BiaM2rYH9_HZwvYxbOWsH8hC1Cy bpe_joint_1000.model\n",
      "Processing file 1SPNljVaDBaLXl0f80BLJAMhPLd7wjQGx bpe_joint_1000.vocab\n",
      "Processing file 1f5J7f_-LcSk2kpRcJLxm-7KdF0hILjDc dev.norm.full.trg\n",
      "Processing file 1fCQ3NzfSsWjBX7A1xD6kNtrn6sB3eBBr dev.src\n",
      "Processing file 1GaGUwMovjqiHZb7Be60loboTPVVBtUAJ dev.trg\n",
      "Processing file 1s2phIvUHQPe3CyNg8M29C2CAj8mAow0C dict_denorm.txt\n",
      "Processing file 1E5_2oFKlM21V4ocd3LMf6T_12xuJ01wd dict_norm.txt\n",
      "Processing file 1Hu4UprunPBnzACvJM7hwE5HIC8UW651Z lefff-3.4.mlex.gz\n",
      "Processing file 10qRvYZ7a5ziVpOzSJAv-2_nAXfSxoNmu levenshtein.py\n",
      "Processing file 1U9ufq5DG_K-7tMBn2mfebae5Tu4gRdIw lstm_denorm.pt\n",
      "Processing file 1JCZi-txsoHNCQLQE5w_IgBzGLY6Cuxbm lstm_norm.pt\n",
      "Processing file 1gf5Xf90c8V3WWyl_JY2_52Y8TBVz_Lzf structure_files.sh\n",
      "Processing file 1UfNk54q97W34X8X4VldUfJ2J6_5yCU18 test.norm.full.trg\n",
      "Processing file 1nbswJbPM5dYbzhFMnhvtTLCBbJM1MKeZ test.src\n",
      "Processing file 1OCoUUT4ZMEKxHwg1AqdmbMAa5HU7zWHq test.trg\n",
      "Processing file 14a_TpkXAX1k5FYe4bYc2q6JMf0xfOt4s train.src\n",
      "Processing file 1xM_kBPZJHqAx5xR_ToNm5PwYo775dieQ train.trg\n",
      "Processing file 1_TODnxG2aJBF_Ad8L6ixUWiTa7Gisgid utils.py\n",
      "Retrieving folder list completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Rfg--VzD1S2F3BQ0O4WztUGO0KI9iaQW\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/align.py\n",
      "100%|██████████████████████████████████████| 2.02k/2.02k [00:00<00:00, 8.61MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=18oYa_BiaM2rYH9_HZwvYxbOWsH8hC1Cy\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/bpe_joint_1000.model\n",
      "100%|████████████████████████████████████████| 252k/252k [00:00<00:00, 4.43MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1SPNljVaDBaLXl0f80BLJAMhPLd7wjQGx\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/bpe_joint_1000.vocab\n",
      "100%|██████████████████████████████████████| 10.5k/10.5k [00:00<00:00, 16.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1f5J7f_-LcSk2kpRcJLxm-7KdF0hILjDc\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/dev.norm.full.trg\n",
      "100%|████████████████████████████████████████| 195k/195k [00:00<00:00, 4.54MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1fCQ3NzfSsWjBX7A1xD6kNtrn6sB3eBBr\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/dev.src\n",
      "100%|████████████████████████████████████████| 198k/198k [00:00<00:00, 3.14MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1GaGUwMovjqiHZb7Be60loboTPVVBtUAJ\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/dev.trg\n",
      "100%|████████████████████████████████████████| 193k/193k [00:00<00:00, 5.38MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1s2phIvUHQPe3CyNg8M29C2CAj8mAow0C\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/dict_denorm.txt\n",
      "100%|██████████████████████████████████████| 9.98k/9.98k [00:00<00:00, 27.7MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1E5_2oFKlM21V4ocd3LMf6T_12xuJ01wd\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/dict_norm.txt\n",
      "100%|██████████████████████████████████████| 9.67k/9.67k [00:00<00:00, 16.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Hu4UprunPBnzACvJM7hwE5HIC8UW651Z\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/lefff-3.4.mlex.gz\n",
      "100%|██████████████████████████████████████| 2.81M/2.81M [00:00<00:00, 14.9MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=10qRvYZ7a5ziVpOzSJAv-2_nAXfSxoNmu\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/levenshtein.py\n",
      "100%|██████████████████████████████████████| 6.48k/6.48k [00:00<00:00, 18.2MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1U9ufq5DG_K-7tMBn2mfebae5Tu4gRdIw\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/lstm_denorm.pt\n",
      "100%|████████████████████████████████████████| 683M/683M [01:12<00:00, 9.41MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1JCZi-txsoHNCQLQE5w_IgBzGLY6Cuxbm\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/lstm_norm.pt\n",
      "100%|████████████████████████████████████████| 683M/683M [01:06<00:00, 10.3MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1gf5Xf90c8V3WWyl_JY2_52Y8TBVz_Lzf\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/structure_files.sh\n",
      "100%|██████████████████████████████████████████| 795/795 [00:00<00:00, 3.24MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1UfNk54q97W34X8X4VldUfJ2J6_5yCU18\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/test.norm.full.trg\n",
      "100%|████████████████████████████████████████| 418k/418k [00:00<00:00, 1.32MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1nbswJbPM5dYbzhFMnhvtTLCBbJM1MKeZ\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/test.src\n",
      "100%|████████████████████████████████████████| 427k/427k [00:00<00:00, 6.19MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OCoUUT4ZMEKxHwg1AqdmbMAa5HU7zWHq\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/test.trg\n",
      "100%|████████████████████████████████████████| 416k/416k [00:00<00:00, 7.01MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=14a_TpkXAX1k5FYe4bYc2q6JMf0xfOt4s\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/train.src\n",
      "100%|██████████████████████████████████████| 1.29M/1.29M [00:00<00:00, 3.26MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1xM_kBPZJHqAx5xR_ToNm5PwYo775dieQ\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/train.trg\n",
      "100%|██████████████████████████████████████| 1.26M/1.26M [00:00<00:00, 4.65MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1_TODnxG2aJBF_Ad8L6ixUWiTa7Gisgid\n",
      "To: /Users/rbawden/Research/tutorials/Tutoriel-Normalisation/data-models/utils.py\n",
      "100%|██████████████████████████████████████████| 408/408 [00:00<00:00, 2.07MB/s]\n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "!gdown https://drive.google.com/drive/folders/1h-qSnPBPZFZQ_kqWIBMhkkFS-6C2b10H?usp=sharing -O data-models --folder\n",
    "!bash structure_files.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Préparation des données à normaliser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions pour lire le contenu d'un fichier ligne par ligne et pour les lire depuis un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lire un fichier ligne par ligne\n",
    "def read_file(filename):\n",
    "  list_sents = []\n",
    "  with open(filename) as fp:\n",
    "    for line in fp:\n",
    "      list_sents.append(line.strip())\n",
    "  return list_sents\n",
    "\n",
    "# écrire une liste de phrases dans un fichier\n",
    "def write_file(list_sents, filename):\n",
    "    with open(filename, 'w') as fp:\n",
    "        for sent in list_sents:\n",
    "            fp.write(sent + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lire le contenu du texte source à normaliser (`dev.src`) et le texte cible 'de référence', c'est-à-dire le texte correctement normalisé (`dev.trg`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_src = read_file('data/dev.src')\n",
    "dev_trg = read_file('data/dev.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser le début des textes sources (src) et cibles (trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src =  1.\n",
      "trg =  1.\n",
      "--\n",
      "src =  1. QVe cette propoſtion, qu'vn eſpace eſt vuidé, repugne au ſens commun.\n",
      "trg =  1. QUe cette proposition, qu'un espace est vidé, répugne au sens commun.\n",
      "--\n",
      "src =  1. QVe tous les corps ont repugnance à ſe ſeparer l'vn de l'autre, & admettre du vuide dans leur interualle;\n",
      "trg =  1. QUe tous les corps ont répugnance à se séparer l'un de l'autre, et admettre du vide dans leur intervalle;\n",
      "--\n",
      "src =  1. QVe tous les corps ont repugnance à ſe ſeparer l'vn de l'autre, & admettre ce vuide apparent dans leur interualle:\n",
      "trg =  1. QUe tous les corps ont répugnance à se séparer l'un de l'autre, et admettre ce vide apparent dans leur intervalle:\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print('src = ', dev_src[i])\n",
    "    print('trg = ', dev_trg[i])\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger le modèle de segmentation en sous-mots (`bpe_joint_1000.model`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece\n",
    "spm = sentencepiece.SentencePieceProcessor(model_file='data/bpe_joint_1000.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer le modèle de segmentation sur les données à normaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_src_sp = spm.encode(dev_src, out_type=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrire le texte pre-traité dans un fichier `dev.sp.src`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file([' '.join(phrase) for phrase in dev_src_sp], 'data/dev.sp.src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser le début du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁1', '.'],\n",
       " ['▁1',\n",
       "  '.',\n",
       "  '▁Q',\n",
       "  'V',\n",
       "  'e',\n",
       "  '▁cette',\n",
       "  '▁prop',\n",
       "  'ost',\n",
       "  'ion',\n",
       "  ',',\n",
       "  '▁qu',\n",
       "  \"'\",\n",
       "  'vn',\n",
       "  '▁esp',\n",
       "  'ace',\n",
       "  '▁est',\n",
       "  '▁v',\n",
       "  'ui',\n",
       "  'd',\n",
       "  'é',\n",
       "  ',',\n",
       "  '▁re',\n",
       "  'p',\n",
       "  'u',\n",
       "  'gne',\n",
       "  '▁au',\n",
       "  '▁sens',\n",
       "  '▁comm',\n",
       "  'un',\n",
       "  '.']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_src_sp[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définir une fonction pour détokeniser (pour plus tard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sp(list_sents):\n",
    "    return [''.join(sent).replace(' ', '').replace('▁', ' ') for sent in list_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser à quoi ressemble le texte détokenisé (Spoiler: il devrait ressembler au texte de départ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 1.',\n",
       " \" 1. QVe cette propostion, qu'vn espace est vuidé, repugne au sens commun.\",\n",
       " \" 1. QVe tous les corps ont repugnance à se separer l'vn de l'autre, & admettre du vuide dans leur interualle;\",\n",
       " \" 1. QVe tous les corps ont repugnance à se separer l'vn de l'autre, & admettre ce vuide apparent dans leur interualle:\",\n",
       " ' 2.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sp(dev_src_sp[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Appliquer le modèle de normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer le modèle de normalisation sur le début des données pre-traitées (ça prend moins de temps pour tester que normaliser tout le texte)\n",
    "\n",
    "Il y aura un message \"UserWarning\", mais vous pouvez l'ignorer - ce n'est pas grave.\n",
    "\n",
    "Explications:\n",
    "- head -n 10 affiche les 10 premières phrases\n",
    "- ces 10 premières lignes sont donné à fairseq-interactive\n",
    "- le résultat va dans `data/dev.sp.norm.trg.10.output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  beams_buf = indices_buf // vocab_size\n",
      "/Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages/fairseq/sequence_generator.py:669: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  unfin_idx = idx // beam_size\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 data/dev.sp.src | fairseq-interactive models/norm/ --source-lang src --target-lang trg --path models/norm/lstm_norm.pt > data/dev.sp.norm.trg.10.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sortie de fairseq-interactive donne quelque chose comme ceci:\n",
    "\n",
    "```\n",
    "S-0     ▁1 .\n",
    "H-0     -0.00011481383990030736 ▁1 .\n",
    "P-0     -0.0000 -0.0003 -0.0000\n",
    "S-1     ▁1 . ▁Q V e ▁cette ▁prop ost ion , ▁qu ' vn ▁esp ace ▁est ▁v ui d é , ▁re p u gne ▁au ▁sens ▁comm un .\n",
    "H-1     -0.039981111884117126   ▁1 . ▁Q U e ▁cette ▁prop ost ion , ▁qu ' un ▁esp ace ▁est ▁v ui d é , ▁rép u gne ▁au ▁sens ▁comm un .\n",
    "P-1     -0.0000 -0.0000 -0.0043 -0.0632 -0.0006 -0.0000 -0.0001 -0.9353 -0.0001 -0.0012 -0.0000 0.0000 -0.0001 -0.0078 -0.0070 -0.0000 -0.0022 -0.1168 -0.0001 -0.0000 -0.0000 -0.0389 -0.0157 -0.0053 -0.0000 -0.0000 -0.0001 -0.0000 -0.0004 -0.0000\n",
    "S-2     ▁1 . ▁Q V e ▁tous ▁les ▁cor p s ▁ont ▁re p u gn ance ▁à ▁se ▁se p are r ▁l ' vn ▁de ▁l ' autre , ▁& ▁ad m ettre ▁du ▁v ui de ▁dans ▁leur ▁in ter u al le ;\n",
    "W-2     0.682   seconds\n",
    "H-2     -0.019450930878520012   ▁1 . ▁Q U e ▁tous ▁les ▁cor p s ▁ont ▁rép u gn ance ▁à ▁se ▁s ép are r ▁l ' un ▁de ▁l ' autre , ▁et ▁ad m ettre ▁du ▁v ui de ▁dans ▁leur ▁in ter v és le ;\n",
    "D-2     -0.019450930878520012   ▁1 . ▁Q U e ▁tous ▁les ▁cor p s ▁ont ▁rép u gn ance ▁à ▁se ▁s ép are r ▁l ' un ▁de ▁l ' autre , ▁et ▁ad m ettre ▁du ▁v ui de ▁dans ▁leur ▁in ter v és le ;\n",
    "P-2     -0.0000 -0.0001 -0.0040 -0.1684 -0.0004 -0.0000 -0.0000 -0.0000 -0.0007 -0.0000 -0.0001 -0.1220 -0.0063 -0.0002 -0.0137 -0.0000 -0.0000 -0.0002 -0.0001 -0.0248 -0.0022 -0.0003 -0.0000 -0.0000 -0.0000 -0.0000 -0.0000 -0.0000 -0.0002 -0.0001 -0.0000 -0.0000 -0.0000 -0.0000 -0.0383 -0.0173 -0.0006 -0.0000 -0.0000 -0.0000 -0.0066 -0.0016 -0.4856 -0.0007 -0.0002 -0.0000\n",
    "```\n",
    "\n",
    "Les informations intéressantes pour l'exemple `i`:\n",
    "\n",
    "- S-i: le texte source\n",
    "- H-i: le score de l'hypothèse et l'hypothèse du modèle (c'est-à-dire la prédiction)\n",
    "- P-i: les scores de chaque sous-token produit par le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour extraire l'hypothèse de ce fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hypothesis(filename):\n",
    "    outputs = []\n",
    "    with open(filename) as fp:\n",
    "        for line in fp:\n",
    "            # seulement les lignes qui commencet par H- (pour Hypothèse)\n",
    "            if 'H-' in line:\n",
    "                # prendre la 3ème colonne (c'est-à-dire l'indice 2)\n",
    "                outputs.append(line.strip().split('\\t')[2])\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraire les hypothèses du fichier produit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁1 .',\n",
       " \"▁1 . ▁Q U e ▁cette ▁prop ost ion , ▁qu ' un ▁esp ace ▁est ▁v ui d é , ▁rép u gne ▁au ▁sens ▁comm un .\",\n",
       " \"▁1 . ▁Q U e ▁tous ▁les ▁cor p s ▁ont ▁rép u gn ance ▁à ▁se ▁s ép are r ▁l ' un ▁de ▁l ' autre , ▁et ▁ad m ettre ▁du ▁v ui de ▁dans ▁leur ▁in ter v és le ;\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_norm_10 = extract_hypothesis('data/dev.sp.norm.trg.10.output')\n",
    "dev_norm_10[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-traiter le texte avec la fonction précedemment définie (dé-segmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 1.',\n",
       " \" 1. QUe cette propostion, qu'un espace est vuidé, répugne au sens commun.\",\n",
       " \" 1. QUe tous les corps ont répugnance à se séparer l'un de l'autre, et admettre du vuide dans leur intervésle;\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_norm_10_postproc = decode_sp(dev_norm_10)\n",
    "dev_norm_10_postproc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrire le résultat dans un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(dev_norm_10_postproc, 'data/dev.norm.10.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Évaluation du résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BLEU: le métrique d'évaluation le plus fréquemment utilisé en traduction automatique\n",
    "- ChrF: CharacterF score (like BLEU but based on n-grams of characters)\n",
    "- TER: translation edit rate\n",
    "\n",
    "Attention : puisque nous avons seulement normalisé 10 phrases, il faut seulement comparer contre les 10 première phrases de référence. En réalité, il faudrait calculer ces scores sur un plus grand nombre de phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLEU = 85.90 94.5/88.4/83.2/78.4 (BP = 1.000 ratio = 1.000 hyp_len = 199 ref_len = 199)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sacrebleu.metrics import BLEU, CHRF, TER\n",
    "bleu = BLEU()\n",
    "bleu.corpus_score(dev_norm_10_postproc, [dev_trg[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chrF2 = 95.73"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrf = CHRF()\n",
    "chrf.corpus_score(dev_norm_10_postproc, [dev_trg[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TER = 6.55"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ter = TER()\n",
    "ter.corpus_score(dev_norm_10_postproc, [dev_trg[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une évaluation plus adaptée : la précision au niveau de chaque mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', '.'], ['1', '.', 'QUe', 'cette', 'proposition>propostion', ',', \"qu'\", 'un', 'espace', 'est', 'vidé>vuidé', ',', 'répugne', 'au', 'sens', 'commun', '.'], ['1', '.', 'QUe', 'tous', 'les', 'corps', 'ont', 'répugnance', 'à', 'se', 'séparer', \"l'\", 'un', 'de', \"l'\", 'autre', ',', 'et', 'admettre', 'du', 'vide>vuide', 'dans', 'leur', 'intervalle>intervésle', ';'], ['1', '.', 'QUe', 'tous', 'les', 'corps', 'ont', 'répugnance', 'à', 'se', 'séparer', \"l'\", 'un', 'de', \"l'\", 'autre', ',', 'et', 'admettre', 'ce', 'vide>vuide', 'apparent', 'dans', 'leur', 'intervalle>intervésle', ':'], ['2', '.'], ['2', '.', 'Que', 'cette', 'horreur', 'ou', 'répugnance', \"qu'\", 'ont', 'tous', 'les', 'corps', ',', \"n'\", 'est', 'pas', 'plus', 'grande', 'pour', 'admettre', 'un', 'grand', 'vide>vuide', ',', \"qu'\", 'un', 'petit', ':'], ['2', '.', 'Que', 'cette', 'horreur', 'où', 'cette', 'répugnance', \"qu'\", 'ont', 'tous', 'les', 'corps', \"n'\", 'est', 'pas', 'plus', 'grande', 'pour', 'admettre', 'un', 'grand', 'vide>vuide', 'apparent', \"qu'\", 'un', 'petit', ':'], ['2', '.', 'Que', 'cette', 'proposition', ',', 'que', 'la', 'Nature', 'abhorre', 'le', 'vide>vuide', ',', 'et', 'néanmoins', \"l'\", 'admet', ',', \"l'\", 'accuse', \"d'\", 'impuissance', ',', 'ou', 'implique', 'contradiction', '.'], ['2', '.', \"Qu'\", 'il', \"n'\", 'est', 'pas', 'plein', 'de', \"l'\", 'air', 'que', 'quelques', 'Philosophes', 'disent', 'être', 'enfermé', 'dans', 'les', 'pores', 'de', 'tous', 'les', 'corps', ',', 'qui', 'se', 'trouverait', 'par', 'ce', 'moyen', ',', 'au', 'dedans', 'de', 'la', 'liqueur', 'qui', 'remplit', 'les', 'tuyaux>tuiaux', '.'], ['2', '.', 'Un', 'soufflet>souflet', 'bien', 'fermé', 'de', 'tous', 'côtés', 'fait', 'le', 'même', 'effet', ',', 'avec', 'une', 'pareille', 'préparation', ':']]\n"
     ]
    }
   ],
   "source": [
    "# d'abord créer un fichier qui ne contient que les 10 première phrases du document cible\n",
    "!head -n 10 data/dev.trg > data/dev.10.trg\n",
    "align_dev_norm_10 = align.align('data/dev.10.trg', 'data/dev.norm.10.trg')\n",
    "\n",
    "print(align_dev_norm_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat de l'alignement est une liste de phrases, où chaque mot de la phrase est comme suit:\n",
    "\n",
    "- le mot tout seul s'il est pareil dans les deux textes (ex : `QUe`)\n",
    "- le mot du premier document et le mot du deuxième document, séparé par \">\" s'ils sont différents (ex : proposition>propostion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '.']\n",
      "['1', '.', 'QUe', 'cette', 'proposition>propostion', ',', \"qu'\", 'un', 'espace', 'est', 'vidé>vuidé', ',', 'répugne', 'au', 'sens', 'commun', '.']\n",
      "['1', '.', 'QUe', 'tous', 'les', 'corps', 'ont', 'répugnance', 'à', 'se', 'séparer', \"l'\", 'un', 'de', \"l'\", 'autre', ',', 'et', 'admettre', 'du', 'vide>vuide', 'dans', 'leur', 'intervalle>intervésle', ';']\n",
      "['1', '.', 'QUe', 'tous', 'les', 'corps', 'ont', 'répugnance', 'à', 'se', 'séparer', \"l'\", 'un', 'de', \"l'\", 'autre', ',', 'et', 'admettre', 'ce', 'vide>vuide', 'apparent', 'dans', 'leur', 'intervalle>intervésle', ':']\n",
      "['2', '.']\n",
      "['2', '.', 'Que', 'cette', 'horreur', 'ou', 'répugnance', \"qu'\", 'ont', 'tous', 'les', 'corps', ',', \"n'\", 'est', 'pas', 'plus', 'grande', 'pour', 'admettre', 'un', 'grand', 'vide>vuide', ',', \"qu'\", 'un', 'petit', ':']\n",
      "['2', '.', 'Que', 'cette', 'horreur', 'où', 'cette', 'répugnance', \"qu'\", 'ont', 'tous', 'les', 'corps', \"n'\", 'est', 'pas', 'plus', 'grande', 'pour', 'admettre', 'un', 'grand', 'vide>vuide', 'apparent', \"qu'\", 'un', 'petit', ':']\n",
      "['2', '.', 'Que', 'cette', 'proposition', ',', 'que', 'la', 'Nature', 'abhorre', 'le', 'vide>vuide', ',', 'et', 'néanmoins', \"l'\", 'admet', ',', \"l'\", 'accuse', \"d'\", 'impuissance', ',', 'ou', 'implique', 'contradiction', '.']\n",
      "['2', '.', \"Qu'\", 'il', \"n'\", 'est', 'pas', 'plein', 'de', \"l'\", 'air', 'que', 'quelques', 'Philosophes', 'disent', 'être', 'enfermé', 'dans', 'les', 'pores', 'de', 'tous', 'les', 'corps', ',', 'qui', 'se', 'trouverait', 'par', 'ce', 'moyen', ',', 'au', 'dedans', 'de', 'la', 'liqueur', 'qui', 'remplit', 'les', 'tuyaux>tuiaux', '.']\n",
      "['2', '.', 'Un', 'soufflet>souflet', 'bien', 'fermé', 'de', 'tous', 'côtés', 'fait', 'le', 'même', 'effet', ',', 'avec', 'une', 'pareille', 'préparation', ':']\n",
      "11\n",
      "216\n",
      "Accuracy = 0.9490740740740741\n"
     ]
    }
   ],
   "source": [
    "num_diff = 0\n",
    "total = 0\n",
    "for sentence in align_dev_norm_10:\n",
    "    print(sentence)\n",
    "    for word in sentence:\n",
    "        if '>' in word:\n",
    "            num_diff += 1\n",
    "        total += 1\n",
    "print('Accuracy = ' + str((total - num_diff)/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tester le modèle de dénormalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparer les données normalisées qui vont être dénormalisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_trg_sp = spm.encode(dev_trg, out_type=str) # tokenise the sentence into subtokens\n",
    "decade_token = '▁<decade=162> ' # special token indicating the decade\n",
    "write_file([' '.join([decade_token] + phrase) for phrase in dev_trg_sp], 'data/dev.sp.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normaliser le texte\n",
    "\n",
    "(10 premières phrases seulement. Vous pouvez faire plus de phrases en modifiant le 10. Vous pouvez tout normaliser en changeant `head -n 10` en `cat`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\r\n",
      "  beams_buf = indices_buf // vocab_size\r\n",
      "/Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages/fairseq/sequence_generator.py:669: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\r\n",
      "  unfin_idx = idx // beam_size\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 data/dev.sp.trg | fairseq-interactive models/denorm --source-lang trg --target-lang src --path models/denorm/lstm_denorm.pt > data/dev.sp.denorm.src.10.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-traiter la sortie du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 1.',\n",
       " \" 1. QVe cette proposition, qu'vn espace est vidé, repugne au sens commun.\",\n",
       " \" 1. QVe tous les corps ont repugnance à se separer l'vn de l'autre, & admettre du vide dans leur interualle;\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_denorm_10 = extract_hypothesis('data/dev.sp.denorm.src.10.output')\n",
    "dev_denorm_10_postproc = decode_sp(dev_denorm_10)\n",
    "write_file(dev_denorm_10_postproc, 'data/dev.sp.denorm.10.src')\n",
    "dev_denorm_10_postproc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a pas mal d'étapes, donc pour faciliter le traitement, voici une fonction qui prend en entrée une liste de phrases et qui fait tout :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalise(sents, decade):\n",
    "    assert int(decade) >=1600 and int(decade) < 1700, 'Your decade must be between 1600 and 1690'\n",
    "    # generate temporary file\n",
    "    filetmp = 'data/tmp_denorm.sp.trg.tmp'\n",
    "    # preprocessing\n",
    "    input_sp = spm.encode(sents, out_type=str)\n",
    "    # add decade token to each sentence\n",
    "    decade_token = '▁<decade=' + str(decade)[:3] + '>'\n",
    "    input_sp_sents = [' '.join([decade_token] + sent) for sent in input_sp]\n",
    "    write_file(input_sp_sents, filetmp)\n",
    "    #print(\"preprocessed = \", input_sp_sents)\n",
    "    # denormalisation\n",
    "    !cat data/tmp_denorm.sp.trg.tmp | fairseq-interactive models/denorm --source-lang trg --target-lang src --path models/denorm/lstm_denorm.pt > data/tmp_denorm.sp.trg.output 2> /tmp/dev\n",
    "    # postprocessing\n",
    "    outputs = extract_hypothesis('data/tmp_denorm.sp.trg.output')\n",
    "    outputs_postproc = decode_sp(outputs)\n",
    "    return outputs_postproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et on peut la tester comme suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" Ie ne sçauois pas qu'il faisoit si beau.\"]\n",
      "[\" Je ne sçavois pas qu'il faisoit si beau.\"]\n"
     ]
    }
   ],
   "source": [
    "print(denormalise([\"Je ne savais pas qu'il faisait si beau.\"], 1640))\n",
    "print(denormalise([\"Je ne savais pas qu'il faisait si beau.\"], 1690))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voici une fonction similaire pour la normalisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(sents):\n",
    "    # generate temporary file\n",
    "    filetmp = 'data/tmp_norm.sp.src.tmp'\n",
    "    # preprocessing\n",
    "    input_sp = spm.encode(sents, out_type=str)\n",
    "    # add decade token to each sentence\n",
    "    input_sp_sents = [' '.join(sent) for sent in input_sp]\n",
    "    write_file(input_sp_sents, filetmp)\n",
    "    #print(\"preprocessed = \", input_sp_sents)\n",
    "    # denormalisation\n",
    "    !cat data/tmp_norm.sp.src.tmp | fairseq-interactive models/norm --source-lang src --target-lang trg --path models/norm/lstm_norm.pt > data/tmp_norm.sp.src.output 2> /tmp/dev\n",
    "    # postprocessing\n",
    "    outputs = extract_hypothesis('data/tmp_norm.sp.src.output')\n",
    "    outputs_postproc = decode_sp(outputs)\n",
    "    return outputs_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise([\"1. QVe cette propostion, qu'vn espace est vuidé, repugne au sens commun.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Quelques extensions (y compris du code à faire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appliquer le modèle sur le texte entier (ou un plus grand nombre de phrases si vous ne voulez pas attendre... ça pourrait être lent).\n",
    "Le fichier entièrement normalisé est aussi disponible ici: `data/dev.norm.full.trg` si vous voulez juste l'évaluer et l'analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_norm = normalise(dev_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(dev_norm, 'data/dev.norm.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Refaire l'évaluation sur le texte entier (pas juste sur les 10 premières phrases) : BLEU, ChrF, TER et exactitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez refaire la normalisation pour le jeu de test maintenant (il se trouve dans `data/test.src`) et l'évaluer/l'analyser\n",
    "\n",
    "La normalisation complète se trouve dans `data/test.norm.full.trg` si vous ne voulez pas attendre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_src = read_file('test.src')\n",
    "test_norm = normalise(test_src)\n",
    "write_file(outputs_test_norm, 'data/test.norm.trg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez aussi faire la même évaluation sur le texte source pour voir quels seraient les scores si on ne changeait rien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire une analyse qualitative de résultats (sur le dev et/ou le test)\n",
    "\n",
    "Complétez cette fonction pour afficher les différences les plus fréquentes.\n",
    "\n",
    "(Calculer les alignements peut prendre pas mal de temps, donc vous pouvez tester avec moins de phrases aussi pendant que vous écrivez la fonction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', '.'], ['1', '.', 'QUe', 'cette', 'proposition>propostion', ',', \"qu'\", 'un', 'espace', 'est', 'vidé>vuidé', ',', 'répugne', 'au', 'sens', 'commun', '.'], ['1', '.', 'QUe', 'tous', 'les', 'corps', 'ont', 'répugnance', 'à', 'se', 'séparer', \"l'\", 'un', 'de', \"l'\", 'autre', ',', 'et', 'admettre', 'du', 'vide>vuide', 'dans', 'leur', 'intervalle>intervésle', ';'], ['1', '.', 'QUe', 'tous', 'les', 'corps', 'ont', 'répugnance', 'à', 'se', 'séparer', \"l'\", 'un', 'de', \"l'\", 'autre', ',', 'et', 'admettre', 'ce', 'vide>vuide', 'apparent', 'dans', 'leur', 'intervalle>intervésle', ':'], ['2', '.'], ['2', '.', 'Que', 'cette', 'horreur', 'ou', 'répugnance', \"qu'\", 'ont', 'tous', 'les', 'corps', ',', \"n'\", 'est', 'pas', 'plus', 'grande', 'pour', 'admettre', 'un', 'grand', 'vide>vuide', ',', \"qu'\", 'un', 'petit', ':'], ['2', '.', 'Que', 'cette', 'horreur', 'où', 'cette', 'répugnance', \"qu'\", 'ont', 'tous', 'les', 'corps', \"n'\", 'est', 'pas', 'plus', 'grande', 'pour', 'admettre', 'un', 'grand', 'vide>vuide', 'apparent', \"qu'\", 'un', 'petit', ':'], ['2', '.', 'Que', 'cette', 'proposition', ',', 'que', 'la', 'Nature', 'abhorre', 'le', 'vide>vuide', ',', 'et', 'néanmoins', \"l'\", 'admet', ',', \"l'\", 'accuse', \"d'\", 'impuissance', ',', 'ou', 'implique', 'contradiction', '.'], ['2', '.', \"Qu'\", 'il', \"n'\", 'est', 'pas', 'plein', 'de', \"l'\", 'air', 'que', 'quelques', 'Philosophes', 'disent', 'être', 'enfermé', 'dans', 'les', 'pores', 'de', 'tous', 'les', 'corps', ',', 'qui', 'se', 'trouverait', 'par', 'ce', 'moyen', ',', 'au', 'dedans', 'de', 'la', 'liqueur', 'qui', 'remplit', 'les', 'tuyaux>tuiaux', '.'], ['2', '.', 'Un', 'soufflet>souflet', 'bien', 'fermé', 'de', 'tous', 'côtés', 'fait', 'le', 'même', 'effet', ',', 'avec', 'une', 'pareille', 'préparation', ':'], ['3', '.', 'Que', 'la', 'force', 'de', 'cette', 'horreur', 'est', 'limitée', ',', 'et', 'pareille', 'à', 'celle', 'avec', 'laquelle', 'de', \"l'\", 'eau', \"d'\", 'une', 'certaine', 'hauteur', 'qui', 'est', 'environ', 'de', 'trente', 'et', 'un', 'pieds', ',', 'tend', 'à', 'couler', 'en', 'bas', '.'], ['3', '.', 'Que', 'la', 'force', 'de', 'cette', 'horreur', 'est', 'limitée', ',', 'et', 'pareille', 'à', 'celle', 'avec', 'laquelle', 'de', \"l'\", 'eau', \"d'\", 'une', 'certaine', 'hauteur', ',', 'qui', 'est', 'à', 'peu', 'près', 'de', 'trente', 'et', 'un', 'pied', ',', 'tend', 'à', 'couler', 'en', 'bas', '.'], ['3', '.', 'Que', 'plusieurs', 'expériences', ',', 'et', 'mêmes', 'journalières>journésières', ',', 'montrent', 'que', 'là', 'Nature', 'ne', 'peut', 'souffrir', 'de', 'vide>vuide', '.'], ['3', '.', \"Qu'\", 'il', \"n'\", 'est', 'pas', 'plein', 'de', \"l'\", 'air', 'que', 'quelques', '-uns', 'estiment>étiment', 'être', 'entre', 'le', 'tuyau>tuiau', ',', 'et', 'la', 'liqueur', 'qui', 'le', 'remplit', ',', 'et', 'enferme', 'dans', 'les', 'interstices', 'ou', 'atomes', 'des', 'corpuscules', 'qui', 'composent', 'ces', 'liqueurs', '.'], ['3', '.', 'Un', 'tuyau>tuiau', 'de', 'verre', 'de', 'quarante', '-six', 'pieds', ',', 'dont', 'un', 'bout', 'est', 'ouvert', ',', 'et', \"l'\", 'autre', 'scellé>seellé', 'hermétiquement>hermetiquement', ',', 'étant', 'rempli', \"d'\", 'eau', ',', 'ou', 'plutôt', 'de', 'vin', 'bien', 'rouge', ',', 'pour', 'être', 'plus', 'visible', ',', 'puis', 'bouché', ',', 'et', 'élevé', 'en', 'cet', 'état', ',', 'et', 'porté', 'perpendiculairement', 'à', \"l'\", 'horizon>horison', ',', \"l'\", 'ouverture>ouuerture', 'bouchée', 'en', 'bas', ',', 'dans', 'un', 'vaisseau', 'plein', \"d'\", 'eau', ',', 'et', 'enfoncé', 'dedans', 'environ', \"d'\", 'un', 'pied', ':'], ['4', '.', 'Que', 'les', 'corps', 'qui', 'bornent', 'ce', 'vide>vuide', 'apparent', ',', 'ont', 'inclination', 'à', 'le', 'remplir', '.'], ['4', '.', 'Que', 'les', 'corps', 'qui', 'bornent', 'ce', 'vide>vuide', ',', 'ont', 'inclination', 'à', 'le', 'remplir', '.'], ['4', '.', \"Qu'\", 'il', \"n'\", 'est', 'pas', 'plein', \"d'\", 'un', 'grain', \"d'\", 'air', 'imperceptible', ',', 'resté', 'par', 'hasard', 'entre', 'la', 'liqueur', 'et', 'le', 'verre', ',', 'ou', 'porté', 'par', 'le', 'doigt', 'qui', 'le', 'bouche', ',', 'ou', 'entré', 'par', \"quelqu'\", 'autre', 'façon', ',', 'qui', 'se', 'raréfierait>rarefierait', 'extraordinairement', ';'], ['4', '.', \"Qu'\", 'une', 'matière', 'imperceptible', ',', 'inouïe>inouie', 'et', 'inconnue', 'à', 'tous', 'les', 'sens', ',', 'remplit', 'cet', 'espace', '.'], ['4', '.', 'Un', 'siphon', 'scalène>scaléne', ',', 'dont', 'la', 'plus', 'longue', 'jambe', 'est', 'de', 'cinquante', 'pieds', ',', 'et', 'la', 'plus', 'courte', 'de', 'quarante', '-cinq', ',', 'étant', 'rempli', \"d'\", 'eau', ',', 'et', 'les', 'deux', 'ouvertures', 'bouchées', 'étant', 'mises', 'dans', 'deux', 'vaisseaux', 'pleins', \"d'\", 'eau', ',', 'et', 'enfoncées', 'environ', \"d'\", 'un', 'pied', ',', 'en', 'sorte', 'que', 'le', 'siphon', 'soit', 'perpendiculaire', 'à', \"l'\", 'horizon>horison', ',', 'et', 'que', 'la', 'surface', 'de', \"l'\", 'eau', \"d'\", 'un', 'vaisseau', 'soit', 'plus', 'haute', 'que', 'la', 'surface', 'de', \"l'\", 'autre', ',', 'de', 'cinq', 'pieds', ':'], ['5', '.', 'Que', 'cette', 'inclination', \"n'\", 'est', 'pas', 'plus', 'forte', 'pour', 'remplir', 'un', 'grand', 'vide>vuide', 'apparent', ',', \"qu'\", 'un', 'petit', '.'], ['5', '.', 'Que', 'cette', 'inclination', \"n'\", 'est', 'pas', 'plus', 'forte', 'pour', 'remplir', 'un', 'grand', 'vide>vuide', ',', \"qu'\", 'un', 'petit', '.'], ['5', '.', 'Que', 'la', 'lumière', 'étant', 'un', 'accident', ',', 'ou', 'une', 'substance', ';'], ['5', '.', \"Qu'\", 'il', \"n'\", 'est', 'pas', 'plein', \"d'\", 'une', 'petite', 'portion', 'du', 'vif', '-argent>argent', 'ou', 'de', \"l'\", 'eau', ',', 'qui', 'étant', 'tirée', \"d'\", 'un', 'côté', 'par', 'les', 'parois', 'du', 'verre', ',', 'et', 'de', \"l'\", 'autre', 'par', 'la', 'force', 'de', 'la', 'liqueur', ',', 'se', 'raréfie>rarefie', 'et', 'se', 'convertit', 'en', 'vapeurs', ';'], ['5', '.', 'Si', \"l'\", 'on', 'met', 'une', 'corde', 'de', 'près', 'de', 'quinze', 'pieds', ',', 'avec', 'un', 'fil', 'attaché', 'au', 'bout', ',', '(laquelle', 'on', 'laisse', 'longtemps>long▁Frs', 'dans', \"l'\", 'eau', 'afin', 'que', \"s'\", 'imbibant', 'peu', 'à', 'peu', ',', \"l'\", 'air', 'qui', 'pourrait>Éait', 'y', 'être', 'enclos', 'en', 'sorte', ')', 'dans', 'un', 'tuyau>tuiau', 'de', 'quinze', 'pieds', 'scellé>seellé', 'par', 'un', 'bout', 'comme', 'dessus', ',', 'et', 'rempli', \"d'\", 'eau', ';'], ['6', '.', 'Que', 'la', 'force', 'de', 'cette', 'inclination', 'est', 'limitée', 'et', 'toujours', 'égale', 'à', 'celle', 'avec', 'laquelle', \"l'\", 'eau', \"d'\", 'une', 'certaine', 'hauteur', ',', 'qui', 'est', 'environ', 'de', 'trente', 'et', 'un', 'pied', ',', 'tend', 'à', 'couler', 'en', 'bas', '.'], ['6', '.', 'Que', 'la', 'force', 'de', 'cette', 'inclination', 'est', 'limitée', ',', 'et', 'toujours', 'pareille', 'à', 'celle', 'avec', 'laquelle', 'de', \"l'\", 'eau', \"d'\", 'une', 'certaine', 'hauteur', ',', 'qui', 'est', 'environ', 'de', 'trente', 'et', 'un', 'pied', ',', 'tend', 'à', 'couler', 'en', 'bas', '.'], ['6', '.', \"Qu'\", 'il', \"n'\", 'est', 'pas', 'plein', 'des', 'esprits', 'de', 'la', 'liqueur', 'qui', 'remplit', 'le', 'tuyau>tuiau', '.'], ['6', '.', 'Une>Vne', 'seringue>syringue', 'avec', 'un', 'piston', 'parfaitement', 'juste', ',', 'étant', 'mise', 'dans', 'le', 'vif', '-argent>argent', ',', 'en', 'sorte', 'que', 'son', 'ouverture', 'y', 'soit', 'enfoncée', 'pour', 'le', 'moins', \"d'\", 'un', 'pouce', ',', 'et', 'que', 'le', 'reste', 'de', 'la', 'seringue>syringue', 'soit', 'élevé', 'perpendiculairement', 'au', 'dehors', ':'], ['7', '.', 'Ayant', 'rempli', 'un', 'siphon', 'de', 'vif', '-argent>argent', ',', 'dont', 'la', 'plus', 'longue', 'jambe', 'a>à', 'dix', 'pieds', ',', 'et', \"l'\", 'autre', 'neuf', 'et', 'demi', ',', 'et', 'mis', 'les', 'deux', 'ouvertures', 'dans', 'deux', 'vaisseaux', 'de', 'vif', '-argent>argent', ',', 'enfoncées', 'environ', \"d'\", 'un', 'pouce>poulce', 'chacune', ',', 'en', 'sorte', 'que', 'la', 'surface', 'du', 'vif', '-argent>argent', 'de', \"l'\", 'un', 'soit', 'plus', 'haute', 'de', 'demi', '-pied>pied', 'que', 'la', 'surface', 'du', 'vif', '-argent>argent', 'de', \"l'\", 'autre', ';'], ['7', '.', \"Qu'\", 'il', \"n'\", 'est', 'pas', 'plein', \"d'\", 'un', 'air', 'plus', 'subtil', 'mêlé', 'parmi', \"l'\", 'air', 'extérieur', ',', 'qui', 'en', 'étant', 'détaché>déché', 'et', 'entré', 'par', 'les', 'pores', 'du', 'verre', ',', 'tendrait', 'toujours', 'à', 'y', 'retourner', ',', 'ou', 'y', 'serait', 'sans', 'cesse', 'attiré', '.'], ['7', '.', \"Qu'\", 'une', 'force', 'plus', 'grande', 'de', 'si', 'peu', 'que', \"l'\", 'on', 'voudra', ',', 'que', 'celle', 'avec', 'laquelle', \"l'\", 'eau', 'de', 'la', 'hauteur', 'de', 'trente', 'et', 'un', 'pieds', ',', 'tend', 'à', 'couler', 'en', 'bas', ',', 'suffit', 'pour', 'faire', 'admettre', 'ce', 'vide>vuide', 'apparent', ',', 'et', 'même', 'si', 'grand', 'que', \"l'\", 'on', 'voudra', ',', \"c'\", 'est', '-à>à', '-dire>dire', ',', 'pour', 'faire', 'désunir>des▁-unir', 'les', 'corps', \"d'\", 'un', 'si', 'grand', 'intervalle>intervésle', 'que', \"l'\", 'on', 'voudra', ',', 'pourvu', \"qu'\", 'il', \"n'\", 'y', 'ait', 'point', \"d'\", 'autre', 'obstacle', 'à', 'leur', 'séparation', 'ni', 'à', 'leur', 'éloignement', ',', 'que', \"l'\", 'horreur', 'que', 'la', 'Nature', 'a', 'pour', 'ce', 'vide>vuide', 'apparent', '.'], ['7', '.', \"Qu'\", 'une', 'force', 'plus', 'grande', 'de', 'si', 'peu', 'que', \"l'\", 'on', 'voudra', ',', 'que', 'celle', 'avec', 'laquelle', \"l'\", 'eau', 'de', 'la', 'hauteur', 'de', 'trente', 'et', 'un', 'pied', 'tend', 'à', 'couler', 'en', 'bas', ',', 'suffit', 'pour', 'faire', 'admette', 'du', 'vide>vuide', ',', 'et', 'même', 'si', 'grand', 'que', \"l'\", 'on', 'voudra', ';'], ['8', '.', 'Le', 'même', 'siphon', 'étant', 'rempli', \"d'\", 'eau', 'entièrement', ',', 'et', 'ensuite>en▁suite', \"d'\", 'une', 'corde', ',', 'comme', 'ci', '-dessus', ',', 'les', 'deux', 'ouvertures', 'étant>étants', 'aussi', 'mises', 'dans', 'les', 'deux', 'mêmes', 'vaisseaux', 'de', 'vif', '-argent>argent', ',', 'quand', 'on', 'tire', 'la', 'corde', 'par', 'une', 'de', 'ces', 'ouvertures', ',', 'le', 'vif', '-argent>argent', 'monte', 'des', 'vaisseaux', 'dans', 'toutes', 'les', 'deux', 'jambes', ':'], ['8', '.', 'Que', \"l'\", 'espace', 'vide>vuide', 'en', 'apparence', ',', \"n'\", 'est', 'rempli', \"d'\", 'aucune', 'des', 'matières', 'qui', 'sont', 'connues', 'dans', 'la', 'Nature', ',', 'et', 'qui', 'tombent', 'sous', 'aucun', 'des', 'sens', '.'], [\"ABRÉGÉ>ABBREGE'\", 'DE', 'LA', 'Conclusion', ',', 'dans', 'laquelle', 'je', 'donne', 'mon', 'sentiment', '.'], [\"ABRÉGÉ>ABBREGE'\", 'DE', 'LA', 'première', 'partie', ',', 'dans', 'laquelle', 'sont', 'rapportées', 'les', 'Expériences', '.'], [\"ABRÉGÉ>ABBREGE'\", 'DE', 'LA', 'deuxième', 'Partie', ',', 'dans', 'laquelle', 'sont', 'rapportées', 'les', 'conséquences', 'de', 'ces', 'Expériences', 'touchant', 'la', 'matière', 'qui', 'peut', 'remplir', 'cet', 'espace', 'vide>vuide', 'en', 'apparence', ',', 'divisée', 'en', 'plusieurs', 'propositions', ',', 'avec', 'leurs', 'démonstrations>demonstrations', '.'], ['AH>Ah', '!', 'Madame…>Madame▁.▁.▁.'], ['APprenez', 'une', 'heureuse', 'nouvelle', ','], ['APrès>APres', 'avoir', 'démontré>demonstré', \"qu'\", 'aucunes', 'des', 'matières', 'qui', 'tombent', 'sous', 'nos', 'sens', ',', 'et', 'dont', 'nous', 'avons', 'connaissance', ',', 'ne', 'remplissent', 'cet', 'espace', 'vide>vuide', 'en', 'apparence', '.'], ['AU', 'ROY', '.'], ['AVEC>AUEC', 'PRIVILÈGE>PRIVILÉGE', 'DU', 'ROI>ROY', '.'], ['Avant', 'que', 'tous', 'les', 'Grecs', 'vous', 'parlent', 'par', 'ma', 'voix', ','], ['AU', 'LECTEUR', '.'], ['AU', 'MÊME', 'Lettre', 'XXIII', '.'], ['AU', 'MÊME', 'Lettre', 'XXII', '.'], ['AU', 'MÊME', 'Lettre', 'XXIX', '.'], ['AU', 'MÊME', 'Lettre', '.'], ['AU', 'MÊME', '.'], ['Accourt', 'tout', 'aussitôt>aussôt', 'en', 'trouve', 'encore', 'un', 'peu', ','], ['Achevez', ',', 'Seigneur', ',', 'votre', 'ambassade', '.'], ['Adieu', 'je', 'vais', 'songer', 'aux', 'choses', 'nécessaires', '.'], ['Adieu', 'rocher', ',', 'caillou', ',', 'pierre', 'de', 'taille', ',', 'et', 'tout', 'ce', \"qu'\", 'il', 'y', 'a', 'de', 'plus', 'dur', 'au', 'monde', '.'], ['Adieu', ',', 'Seigneur', ',>▁', 'régnez', ',', 'je', 'ne', 'vous', 'verrai', 'plus', '.'], ['Adieu', ',', 'je', 'me', 'retire', ',', 'et', 'je', 'ne', 'puis', 'plus', 'endurer', \"qu'\", 'on', \"m'\", 'outrage', 'de', 'cette', 'sorte', '.'], ['Adieu', ',', \"j'\", 'irai', 'chez', 'vous', 'tantôt', 'vous', 'rendre', 'grâce', '.'], ['Adieu', '.', 'Tu', 'peux', 'partir', '.', 'Je', 'demeure', 'en>eni▁', 'Épire>▁gnepire', ','], ['Affectait', 'un', 'mépris', 'qui', 'marquait', 'son', 'estime', ','], ['Afin', 'que', 'dans', 'ce', 'temps', 'la', 'bile', 'se', 'tempère', ','], ['Afin', \"qu'\", 'un', 'jeune', 'fou', 'dont', 'elle', \"s'\", 'amourache'], ['Ah', 'Ciel', '.'], ['Ah', 'Varus', '!', 'que', 'je', 'plains', ',', 'que', \"j'\", 'admire', 'ton', 'sort', '!'], ['Ah', 'ingrate', 'Bergère', \"(s'\", 'écria', 'incontinent', 'Lycidas', ')', 'je', 'tiendrai', 'le', 'Ciel', 'pour', 'être', 'de', 'vos', 'complices', ',', \"s'\", 'il', 'ne', 'punit', 'cette', 'injustice', 'en', 'vous', '?'], ['Ah', '!'], ['Ah', '!', 'Madame', ',', 'il', 'est', 'vrai', ',', 'quelque', 'effort', 'que', 'je', 'fasse', ','], ['Ah', '!', 'Madame', ',', 'à', 'mes', 'yeux', \"n'\", 'offrez', 'point', 'son', 'mérite', ';'], ['Ah', '!', \"Qu'\", 'un', 'aveu', 'si', 'doux', 'aurait', 'lieu', 'de', 'me', 'plaire', '!'], ['Ah', '!', \"c'\", 'en', 'est', 'trop', ',', 'Seigneur', '.'], ['Ah', '!', 'je', 'ne', 'croyais', 'pas', \"qu'\", 'il', 'fût', 'si', 'près', \"d'\", 'ici', '.'], ['Ah', '!', \"j'\", 'ai', 'perdu', \"l'\", 'objet>objet,', 'pour', 'qui', \"j'\", 'aimais', 'à', 'vivre', ','], ['Ah', '!', 'non', ',', 'mourons', 'plutôt', 'que', 'vivre', 'lâchement', '.'], ['Ah', '!', 'plutôt', 'cette', 'main', 'dans', 'le', 'sang', 'du', 'Barbare…>Barbare▁.▁.▁.'], ['Ah', '!', 'que', 'je', 'crains', ',', 'Madame', ',', 'un', 'calme>cal', 'si', 'funeste', '!'], ['Ah', '!', 'tout', 'est', 'ruiné', ';'], ['Ah', '!', 'souffrez', 'dans', 'les', 'maux>maux,', 'où', 'mon', 'destin', \"m'\", 'expose', ','], ['Ah', ',', 'Monsieur', ',', 'quel', 'Arrêt', '!'], ['Ainsi', 'ceux', 'qui', 'ne', 'font', 'que', 'feindre', 'ces', 'sentiments', 'sont', 'bien', 'mal>mal▁', '-heureux>▁heureux', 'de', 'contraindre', 'leur', 'naturel', 'pour', 'se', 'rendre', 'les', 'plus', 'impertinents', 'des', 'hommes', '.'], ['Ainsi', 'donc', 'mes', 'bontés', 'vous', 'fatiguent', 'peut', '-être', '?'], ['Ainsi', 'donc', 'tout', 'prêt', 'à', 'le', 'quitter', ','], ['Ainsi', 'il', 'arrive', 'que', 'si', 'elle', 'se', 'vide>vuide', 'un', 'peu', ',', 'la', 'pression', 'intérieure', 'pousse', 'pourtant', 'toujours', 'de', \"l'\", 'eau', 'contre', 'la', 'soupape', 'P', ',', 'par', 'ledit', 'tuyau>tuiau', 'OO', ',', 'ce', 'qui', 'la', 'rend', 'plus', 'exacte', ',', 'et', 'aide', 'aussi', 'à', 'connaître', 'incontinent', 'quand', 'elle', 'laisse', 'échapper', 'quelque', 'chose', '.'], ['Ainsi', 'quand', 'un', 'poids', \"d'\", 'une', 'livre', 'est', 'à', \"l'\", 'extrémité', 'M', ',', 'et', 'que', 'la', 'soupape', 'P', 'laisse', 'échapper', 'quelque', 'chose', ';'], ['Ainsi', 'que', 'je', 'voudrai', ',', 'je', 'tournerai', 'cette', 'âme', '.'], ['Ainsi', 'tous', 'mes', 'efforts', 'ne', 'seront', 'que', 'fumée', '.>,'], ['Ainsi', 'soit', '-il', '.'], ['Ainsi', ',', 'je', 'me', 'contente', 'de', 'montrer', 'un', 'grand', 'espace', 'vide>vuide', ',', 'et', 'laisse', 'à', 'des', 'personnes', 'savantes', 'et', 'curieuses', 'à', 'éprouver', 'ce', 'qui', 'se', 'fait', 'dans', 'un', 'tel', 'espace', ':'], ['Ainsi>Ainsi,', 'tous', 'trois', ',', 'Seigneur', ',', 'par', 'vos', 'soins', 'réunis', ','], ['Ainsi', ',', 'sans', 'différer…>différer▁...', 'Madame', ',', 'vous', 'tremblez', ','], ['Ait', 'pris', 'chez', 'moi', 'les', 'traits', \"qu'\", 'il', 'lance', 'contre', 'vous', ','], ['Ait', 'rendu', 'son', 'hommage', 'à', 'ta', 'Divinité', '.'], ['Allez', 'joindre', 'Hannibal', 'mon', 'illustre', 'ennemi', ';'], ['Allez', '-vous>vous', '-en>en', 'faire', 'la', 'paix', 'ensemble', ',', 'et', 'tâchez', 'de', \"l'\", 'apaiser', 'par', 'des', 'excuses', 'de', 'votre', 'emportement', '.'], ['Allons', 'aux', 'Grecs', 'livrer', 'le', 'Fils', \"d'\", 'Hector', '.'], ['Allons', 'dans', 'nos', 'plaisirs', 'satisfaire', 'son', 'zèle', ','], ['Allons', 'il', \"s'\", 'agit', 'seulement', 'de', 'désabuser>désabufer', 'le', 'père', 'et', 'la', 'mère', ',', 'et', 'je', 'pourrai', 'trouver', 'peut', '-être', 'quelque', 'moyen', \"d'\", 'y', 'réussir', '.'], ['Allons', 'mon', 'ancien', 'vainqueur', '(dit', '-il>il', 'à', 'ce', 'fameux', 'Pirate', 'qui', \"n'\", 'avait', 'point', 'déguisé', 'son', 'véritable', 'Nom', ',', 'parce', \"qu'\", 'étant', 'fort', 'commun', 'parmi', 'les', 'Grecs', ',', 'il', 'ne', 'pouvait', 'pas', 'le', 'faire', 'reconnaître', ')', 'allons', 'secourir', 'cette', 'personne', 'illustre', ':'], ['Allons', ',', 'exécutons>executons', 'les', 'volontés', \"d'\", 'Auguste', ','], ['Allons', '.', \"C'\", 'est', 'à', 'moi', 'seule', ',', 'à', 'me', 'rendre', 'justice', '.'], ['Alors', 'le', 'Roi', 'et', 'la', 'Reine', 'après', 'avoir', 'baisé', 'leur', 'chère', 'enfant', 'sans', \"qu'\", 'elle', \"s'\", 'éveillât', ',', 'sortirent', 'du', 'château', ',', 'et', 'firent', 'publier', 'des', 'défenses', 'à', 'qui', 'que', 'ce', 'soit', \"d'\", 'en', 'approcher', '.'], ['Amitié', ',', 'sang', ',', 'amour', ',', 'je', 'cède', 'à', 'votre', 'effort', ',']]\n"
     ]
    }
   ],
   "source": [
    "!head -n 100 data/dev.trg > data/dev.100.trg\n",
    "!head -n 100 data/dev.norm.full.trg > data/dev.norm.100.trg\n",
    "alignments_dev = align.align('data/dev.100.trg', 'data/dev.norm.100.trg')\n",
    "#alignments_dev = align.align('data/dev.trg', 'data/dev.norm.full.trg') # décommenter pour faire sur le jeu entier\n",
    "\n",
    "\n",
    "# get alignments\n",
    "def print_most_frequent_diffs(alignments, show_n=10):\n",
    "    # TODO\n",
    "    return\n",
    "\n",
    "print_most_frequent_diffs(alignments_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire une analyse qualitative des différences entre un texte source et cible pour visualiser les corresondences de normalisation.\n",
    "\n",
    "Idéalement ceci se fait sur le jeu d'entraînement (`data/train.src` et `data/train.trg`), mais ça risque de prendre trop de temps pour ce TP, donc prenez une sous-partie des exemples (en utilisant `head` comme avant) !\n",
    "\n",
    "- lire les deux fichiers\n",
    "- appliquer l'alignement\n",
    "- utiliser la fonction `print_most_frequent_diffs` (précédemment utilisée pour comparer la prédiction contre la référence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer un modèle baseline par règles. Comme ressources supplémentaires, vous avez un lexique de mots en français contemporain et quelques fonctions\n",
    "\n",
    "Idées possibles:\n",
    "\n",
    "- remplacer les caractères qui changent systématiquement en utilisant la fonction `replace(avant, après)` : `word = word.replace('ſ', 's')`\n",
    "- remplacer les caractères en utilisant les expressions régulières (si vous les connaissez) : `word = word.replace('vn(e?)', r'un\\1')`\n",
    "- parcourir les mots de la phrase et si le mot n'apparaît pas dans le lexique, trouver le mot du lexique qui est le plus similaire. Quelques idées de fonctions de similarité:\n",
    "  - la distance de levenshtein (la fonction est donnée ci-dessous)\n",
    "  - une fonction plus simple qui compare le nombre de caractères en commun entre les deux mots (à faire)\n",
    "  - il serait peut-être sage de normaliser cette dernière similarité par la longueur des mots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a lexicon in the mlex format\n",
    "import gzip\n",
    "def read_lexicon(filename):\n",
    "    words = []\n",
    "    with gzip.open(filename, 'rt') as fp:\n",
    "        for line in fp:\n",
    "            words.append(line.split('\\t')[0])\n",
    "    return words\n",
    "\n",
    "# calculate the levenshtein distance\n",
    "def similarity_levenshtein(word1, word2):\n",
    "    dist, matrix, backpointers = levenshtein('@' + word1, '@' + word2)\n",
    "    return dist\n",
    "\n",
    "# calculate the number of common characters between the two words\n",
    "def similarity_common_chars(word1, word2):\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = read_lexicon('data/lefff-3.4.mlex.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le lexique contient 549274 entrées.\n"
     ]
    }
   ],
   "source": [
    "print('Le lexique contient ' + str(len(lexicon)) + ' entrées.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that normalises a sentence given a function that normalises a word\n",
    "import utils\n",
    "from importlib import reload\n",
    "reload(utils)\n",
    "def normalise_sent(sent, normalise_word_function):\n",
    "    norm_sent = []\n",
    "    # go through the sentence word by word (the tokenisation function is very approximate here!)\n",
    "    for word in utils.basic_tokenise(sent).split():\n",
    "        norm_sent.append(normalise_word_function(word))\n",
    "    return utils.detokenise(' '.join(norm_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns the word itself\n",
    "def return_word(word):\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"QVe cette propoſtion, qu'vn eſpace eſt vuidé\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# illustration of how this could work (using just the function that returns the original word)\n",
    "normalise_word_function = return_word\n",
    "normalise_sent(\"QVe cette propoſtion, qu'vn eſpace eſt vuidé\", normalise_word_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that replaces the long s\n",
    "def replace_long_s(word):\n",
    "    word = word.replace('ſ', 's')\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on peut tester avec une autre petite fonction qui ne fait que remplacer les ſ par s :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"QVe cette propostion, qu'vn espace est vuidé\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalise_word_function = replace_long_s\n",
    "normalise_sent(\"QVe cette propoſtion, qu'vn eſpace eſt vuidé\", normalise_word_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez créer une fonction qui contient plus de remplacements (comme `word.replace(before, after)`).\n",
    "\n",
    "Parfois, un remplacement peut être contextuel, donc si vous connaissez les expressions régulières vous pouvez les utiliser aussi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"QUe cette propostion, qu'un espace est vuidé\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def replace_regex(word):\n",
    "    word = word.replace('ſ', 's')\n",
    "    word = re.sub(\"([Qq])v\", r'\\1u', word)\n",
    "    word = re.sub(\"([Qq])V\", r'\\1U', word)\n",
    "    word = re.sub(\"('?)vn(e?)\", r'\\1un\\2', word)\n",
    "    return word\n",
    "\n",
    "normalise_word_function = replace_regex\n",
    "normalise_sent(\"QVe cette propoſtion, qu'vn eſpace eſt vuidé\", normalise_word_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN8AweSe1ASxQbXHW5LKQ6B",
   "include_colab_link": true,
   "name": "Tutoriel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
