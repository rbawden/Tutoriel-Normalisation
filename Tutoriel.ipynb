{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rbawden/Tutoriel-Normalisation/blob/main/Tutoriel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorations sur la normalisation du français moderne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup de l'environnement, téléchargement des fichiers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installer les paquets python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52\n",
      "  Using cached fairseq-1.0.0a0+5a75b07-cp37-cp37m-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: cffi in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (1.15.0)\n",
      "Requirement already satisfied: omegaconf<2.1 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (2.0.5)\n",
      "Requirement already satisfied: torch in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (1.10.0)\n",
      "Requirement already satisfied: hydra-core<1.1 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (1.0.7)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (2.0.0)\n",
      "Requirement already satisfied: cython in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (0.29.24)\n",
      "Requirement already satisfied: numpy in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (1.21.4)\n",
      "Requirement already satisfied: regex in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (2021.11.10)\n",
      "Requirement already satisfied: tqdm in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (4.62.3)\n",
      "Requirement already satisfied: importlib-resources in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from hydra-core<1.1->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (5.4.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from hydra-core<1.1->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (4.8)\n",
      "Requirement already satisfied: typing-extensions in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from omegaconf<2.1->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (4.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from omegaconf<2.1->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (6.0)\n",
      "Requirement already satisfied: colorama in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (0.4.4)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (0.8.9)\n",
      "Requirement already satisfied: portalocker in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (2.3.2)\n",
      "Requirement already satisfied: pycparser in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from cffi->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (2.21)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from importlib-resources->hydra-core<1.1->fairseq@ git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52) (3.6.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (0.1.96)\n",
      "Requirement already satisfied: sacrebleu in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: hydra-core in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (1.0.7)\n",
      "Requirement already satisfied: omegaconf==2.0.5 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (2.0.5)\n",
      "Requirement already satisfied: gdown==4.2.0 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (4.2.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from omegaconf==2.0.5) (6.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from omegaconf==2.0.5) (4.0.0)\n",
      "Requirement already satisfied: requests[socks] in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from gdown==4.2.0) (2.26.0)\n",
      "Requirement already satisfied: tqdm in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from gdown==4.2.0) (4.62.3)\n",
      "Requirement already satisfied: six in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from gdown==4.2.0) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from gdown==4.2.0) (4.10.0)\n",
      "Requirement already satisfied: filelock in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from gdown==4.2.0) (3.4.0)\n",
      "Requirement already satisfied: regex in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu) (2021.11.10)\n",
      "Requirement already satisfied: colorama in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu) (0.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu) (1.21.4)\n",
      "Requirement already satisfied: portalocker in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu) (2.3.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from sacrebleu) (0.8.9)\n",
      "Requirement already satisfied: importlib-resources in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from hydra-core) (5.4.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from hydra-core) (4.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from beautifulsoup4->gdown==4.2.0) (2.3.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from importlib-resources->hydra-core) (3.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from requests[socks]->gdown==4.2.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from requests[socks]->gdown==4.2.0) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from requests[socks]->gdown==4.2.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from requests[socks]->gdown==4.2.0) (2021.10.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages (from requests[socks]->gdown==4.2.0) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install fairseq@git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52 \n",
    "!pip install sentencepiece sacrebleu hydra-core omegaconf==2.0.5 gdown==4.2.0 \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Télécharger les données et les modèles depuis Google Drive et structures-les dans les dossiers `data/`, `models/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!bash download_files.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Préparation des données à normaliser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions pour lire le contenu d'un fichier ligne par ligne et pour les lire depuis un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lire un fichier ligne par ligne\n",
    "def read_file(filename):\n",
    "  list_sents = []\n",
    "  with open(filename) as fp:\n",
    "    for line in fp:\n",
    "      list_sents.append(line.strip())\n",
    "  return list_sents\n",
    "\n",
    "# écrire une liste de phrases dans un fichier\n",
    "def write_file(list_sents, filename):\n",
    "    with open(filename, 'w') as fp:\n",
    "        for sent in list_sents:\n",
    "            fp.write(sent + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lire le contenu du texte source à normaliser (`dev.src`) et le texte cible 'de référence', c'est-à-dire le texte correctement normalisé (`dev.trg`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_src = read_file('data/dev.src')\n",
    "data_trg = read_file('data/dev.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser le début des textes sources (src) et cibles (trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src =  1.\n",
      "trg =  1.\n",
      "--\n",
      "src =  1. QVe cette propoſtion, qu'vn eſpace eſt vuidé, repugne au ſens commun.\n",
      "trg =  1. QUe cette proposition, qu'un espace est vidé, répugne au sens commun.\n",
      "--\n",
      "src =  1. QVe tous les corps ont repugnance à ſe ſeparer l'vn de l'autre, & admettre du vuide dans leur interualle;\n",
      "trg =  1. QUe tous les corps ont répugnance à se séparer l'un de l'autre, et admettre du vide dans leur intervalle;\n",
      "--\n",
      "src =  1. QVe tous les corps ont repugnance à ſe ſeparer l'vn de l'autre, & admettre ce vuide apparent dans leur interualle:\n",
      "trg =  1. QUe tous les corps ont répugnance à se séparer l'un de l'autre, et admettre ce vide apparent dans leur intervalle:\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print('src = ', data_src[i])\n",
    "    print('trg = ', data_trg[i])\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger le modèle de segmentation en sous-mots (`bpe_joint_1000.model`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece\n",
    "spm = sentencepiece.SentencePieceProcessor(model_file='data/bpe_joint_1000.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer le modèle de segmentation sur les données à normaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_src_sp = spm.encode(data_src, out_type=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrire le texte pre-traité dans un fichier `dev.sp.src`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file([' '.join(phrase) for phrase in data_src_sp], 'data/dev.sp.src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser le début du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁1', '.'],\n",
       " ['▁1',\n",
       "  '.',\n",
       "  '▁Q',\n",
       "  'V',\n",
       "  'e',\n",
       "  '▁cette',\n",
       "  '▁prop',\n",
       "  'ost',\n",
       "  'ion',\n",
       "  ',',\n",
       "  '▁qu',\n",
       "  \"'\",\n",
       "  'vn',\n",
       "  '▁esp',\n",
       "  'ace',\n",
       "  '▁est',\n",
       "  '▁v',\n",
       "  'ui',\n",
       "  'd',\n",
       "  'é',\n",
       "  ',',\n",
       "  '▁re',\n",
       "  'p',\n",
       "  'u',\n",
       "  'gne',\n",
       "  '▁au',\n",
       "  '▁sens',\n",
       "  '▁comm',\n",
       "  'un',\n",
       "  '.']]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_src_sp[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définir une fonction pour détokeniser (pour plus tard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sp(list_sents):\n",
    "    return [''.join(sent).replace(' ', '').replace('▁', ' ') for sent in list_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser à quoi ressemble le texte détokenisé (Spoiler: il devrait ressembler au texte de départ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 1.',\n",
       " \" 1. QVe cette propostion, qu'vn espace est vuidé, repugne au sens commun.\",\n",
       " \" 1. QVe tous les corps ont repugnance à se separer l'vn de l'autre, & admettre du vuide dans leur interualle;\",\n",
       " \" 1. QVe tous les corps ont repugnance à se separer l'vn de l'autre, & admettre ce vuide apparent dans leur interualle:\",\n",
       " ' 2.']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sp(data_src_sp[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Appliquer le modèle de normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer le modèle de normalisation sur le début des données pre-traitées (ça prend moins de temps pour tester que normaliser tout le texte)\n",
    "\n",
    "Il y aura un message \"UserWarning\", mais vous pouvez l'ignorer - ce n'est pas grave.\n",
    "\n",
    "Explications:\n",
    "- head -n 10 affiche les 10 premières phrases\n",
    "- ces 10 premières lignes sont donné à fairseq-interactive\n",
    "- le résultat va dans `data/dev.sp.norm.trg.10.output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\r\n",
      "  beams_buf = indices_buf // vocab_size\r\n",
      "/Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages/fairseq/sequence_generator.py:669: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\r\n",
      "  unfin_idx = idx // beam_size\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 data/dev.sp.src | fairseq-interactive models/norm/ --source-lang src --target-lang trg --path models/norm/lstm_norm.pt > data/dev.sp.norm.trg.10.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sortie de fairseq-interactive donne quelque chose comme ceci:\n",
    "\n",
    "```\n",
    "S-0     ▁1 .\n",
    "H-0     -0.00011481383990030736 ▁1 .\n",
    "P-0     -0.0000 -0.0003 -0.0000\n",
    "S-1     ▁1 . ▁Q V e ▁cette ▁prop ost ion , ▁qu ' vn ▁esp ace ▁est ▁v ui d é , ▁re p u gne ▁au ▁sens ▁comm un .\n",
    "H-1     -0.039981111884117126   ▁1 . ▁Q U e ▁cette ▁prop ost ion , ▁qu ' un ▁esp ace ▁est ▁v ui d é , ▁rép u gne ▁au ▁sens ▁comm un .\n",
    "P-1     -0.0000 -0.0000 -0.0043 -0.0632 -0.0006 -0.0000 -0.0001 -0.9353 -0.0001 -0.0012 -0.0000 0.0000 -0.0001 -0.0078 -0.0070 -0.0000 -0.0022 -0.1168 -0.0001 -0.0000 -0.0000 -0.0389 -0.0157 -0.0053 -0.0000 -0.0000 -0.0001 -0.0000 -0.0004 -0.0000\n",
    "S-2     ▁1 . ▁Q V e ▁tous ▁les ▁cor p s ▁ont ▁re p u gn ance ▁à ▁se ▁se p are r ▁l ' vn ▁de ▁l ' autre , ▁& ▁ad m ettre ▁du ▁v ui de ▁dans ▁leur ▁in ter u al le ;\n",
    "W-2     0.682   seconds\n",
    "H-2     -0.019450930878520012   ▁1 . ▁Q U e ▁tous ▁les ▁cor p s ▁ont ▁rép u gn ance ▁à ▁se ▁s ép are r ▁l ' un ▁de ▁l ' autre , ▁et ▁ad m ettre ▁du ▁v ui de ▁dans ▁leur ▁in ter v és le ;\n",
    "D-2     -0.019450930878520012   ▁1 . ▁Q U e ▁tous ▁les ▁cor p s ▁ont ▁rép u gn ance ▁à ▁se ▁s ép are r ▁l ' un ▁de ▁l ' autre , ▁et ▁ad m ettre ▁du ▁v ui de ▁dans ▁leur ▁in ter v és le ;\n",
    "P-2     -0.0000 -0.0001 -0.0040 -0.1684 -0.0004 -0.0000 -0.0000 -0.0000 -0.0007 -0.0000 -0.0001 -0.1220 -0.0063 -0.0002 -0.0137 -0.0000 -0.0000 -0.0002 -0.0001 -0.0248 -0.0022 -0.0003 -0.0000 -0.0000 -0.0000 -0.0000 -0.0000 -0.0000 -0.0002 -0.0001 -0.0000 -0.0000 -0.0000 -0.0000 -0.0383 -0.0173 -0.0006 -0.0000 -0.0000 -0.0000 -0.0066 -0.0016 -0.4856 -0.0007 -0.0002 -0.0000\n",
    "```\n",
    "\n",
    "Les informations intéressantes pour l'exemple `i`:\n",
    "\n",
    "- S-i: le texte source\n",
    "- H-i: le score de l'hypothèse et l'hypothèse du modèle (c'est-à-dire la prédiction)\n",
    "- P-i: les scores de chaque sous-token produit par le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour extraire l'hypothèse de ce fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hypothesis(filename):\n",
    "    outputs = []\n",
    "    with open(filename) as fp:\n",
    "        for line in fp:\n",
    "            # seulement les lignes qui commencet par H- (pour Hypothèse)\n",
    "            if 'H-' in line:\n",
    "                # prendre la 3ème colonne (c'est-à-dire l'indice 2)\n",
    "                outputs.append(line.strip().split('\\t')[2])\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraire les hypothèses du fichier produit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁1 .',\n",
       " \"▁1 . ▁Q U e ▁cette ▁prop ost ion , ▁qu ' un ▁esp ace ▁est ▁v ui d é , ▁rép u gne ▁au ▁sens ▁comm un .\",\n",
       " \"▁1 . ▁Q U e ▁tous ▁les ▁cor p s ▁ont ▁rép u gn ance ▁à ▁se ▁s ép are r ▁l ' un ▁de ▁l ' autre , ▁et ▁ad m ettre ▁du ▁v ui de ▁dans ▁leur ▁in ter v és le ;\"]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = extract_hypothesis('data/dev.sp.norm.trg.10.output')\n",
    "outputs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-traiter le texte avec la fonction précedemment définie (dé-segmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁1 .',\n",
       " \"▁1 . ▁Q U e ▁cette ▁prop ost ion , ▁qu ' un ▁esp ace ▁est ▁v ui d é , ▁rép u gne ▁au ▁sens ▁comm un .\",\n",
       " \"▁1 . ▁Q U e ▁tous ▁les ▁cor p s ▁ont ▁rép u gn ance ▁à ▁se ▁s ép are r ▁l ' un ▁de ▁l ' autre , ▁et ▁ad m ettre ▁du ▁v ui de ▁dans ▁leur ▁in ter v és le ;\"]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_postproc = decode_sp(outputs)\n",
    "outputs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrire le résultat dans un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(outputs_postproc, 'data/dev.sp.norm.10.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Évaluation du résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BLEU: le métrique d'évaluation le plus fréquemment utilisé en traduction automatique\n",
    "- ChrF: CharacterF score (like BLEU but based on n-grams of characters)\n",
    "- TER: translation edit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLEU = 85.90 94.5/88.4/83.2/78.4 (BP = 1.000 ratio = 1.000 hyp_len = 199 ref_len = 199)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sacrebleu.metrics import BLEU, CHRF, TER\n",
    "bleu = BLEU()\n",
    "bleu.corpus_score(outputs_postproc, [data_trg[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chrF2 = 95.73"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrf = CHRF()\n",
    "chrf.corpus_score(outputs_postproc, [data_trg[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TER = 6.55"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ter = TER()\n",
    "ter.corpus_score(outputs_postproc, [data_trg[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une évaluation plus adaptée : la précision au niveau de chaque mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'align' from '/Users/rbawden/Research/tutorials/Tutoriel-Normalisation/align.py'>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import align\n",
    "import importlib\n",
    "importlib.reload(align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments = align.align('data/dev.sp.src', 'data/dev.sp.norm.trg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8638743455497382\n"
     ]
    }
   ],
   "source": [
    "num_diff = 0\n",
    "total = 0\n",
    "for sentence in alignments:\n",
    "    for word in sentence:\n",
    "        if '>' in word:\n",
    "            num_diff += 1\n",
    "        total += 1\n",
    "print('Accuracy = ' + str(num_diff/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tester le modèle de dénormalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparer les données normalisées qui vont être dénormalisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trg_sp = spm.encode(data_trg, out_type=str) # segmenter le texte en sous-mots\n",
    "decade_token = '▁<decade=162> '\n",
    "write_file([' '.join([decade_token] + phrase) for phrase in data_trg_sp], 'data/dev.sp.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normaliser le texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\r\n",
      "  beams_buf = indices_buf // vocab_size\r\n",
      "/Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages/fairseq/sequence_generator.py:669: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\r\n",
      "  unfin_idx = idx // beam_size\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 data/dev.sp.trg | fairseq-interactive models/denorm --source-lang trg --target-lang src --path models/denorm/lstm_denorm.pt > data/dev.sp.denorm.src.10.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-traiter la sortie du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 1.',\n",
       " \" 1. QVe cette proposition, qu'vn espace est vidé, repugne au sens commun.\",\n",
       " \" 1. QVe tous les corps ont repugnance à se separer l'vn de l'autre, & admettre du vide dans leur interualle;\"]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = extract_hypothesis('data/dev.sp.denorm.src.10.output')\n",
    "outputs_postproc = decode_sp(outputs)\n",
    "write_file(outputs_postproc, 'data/dev.sp.denorm.10.src')\n",
    "outputs_postproc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalise(sent, decade):\n",
    "    assert int(decade) >=1600 and int(decade) < 1700, 'Your decade must be between 1600 and 1690'\n",
    "    # generate temporary file\n",
    "    filetmp = 'data/tmp_denorm.sp.trg.tmp'\n",
    "    # preprocessing\n",
    "    input_sp = spm.encode(sent, out_type=str)\n",
    "    # add decade token to each sentence\n",
    "    decade_token = '▁<decade=' + str(decade)[:3] + '>'\n",
    "    input_sp_sents = [' '.join([decade_token] + input_sp)]\n",
    "    write_file(input_sp_sents, filetmp)\n",
    "    print(input_sp_sents)\n",
    "    # denormalisation\n",
    "    !cat data/tmp_denorm.sp.trg.tmp | fairseq-interactive models/denorm --source-lang trg --target-lang src --path models/denorm/lstm_denorm.pt > data/tmp_denorm.sp.trg.tmp.output 2> /tmp/dev\n",
    "    # postprocessing\n",
    "    outputs = extract_hypothesis('data/tmp_denorm.sp.trg.tmp.output')\n",
    "    outputs_postproc = decode_sp(outputs)\n",
    "    return outputs_postproc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁<decade=162> ▁Il ▁est ▁beau .']\n",
      " Il est beau.\n"
     ]
    }
   ],
   "source": [
    "print(denormalise(\"Il est beau.\", 1620))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(sent):\n",
    "    # generate temporary file\n",
    "    filetmp = 'data/tmp_norm.sp.src.tmp'\n",
    "    # preprocessing\n",
    "    input_sp = spm.encode(sent, out_type=str)\n",
    "    # add decade token to each sentence\n",
    "    input_sp_sents = [' '.join(input_sp)]\n",
    "    write_file(input_sp_sents, filetmp)\n",
    "    print(\"preprocessed = \", input_sp_sents)\n",
    "    # denormalisation\n",
    "    !cat data/tmp_norm.sp.src.tmp | fairseq-interactive models/norm --source-lang src --target-lang trg --path models/norm/lstm_norm.pt > data/tmp_norm.sp.src.tmp.output 2> /tmp/dev\n",
    "    # postprocessing\n",
    "    outputs = extract_hypothesis('data/tmp_norm.sp.src.tmp.output')\n",
    "    outputs_postproc = decode_sp([outputs])\n",
    "    return outputs_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed =  [\"▁1 . ▁Q V e ▁cette ▁prop ost ion , ▁qu ' vn ▁esp ace ▁est ▁v ui d é , ▁re p u gne ▁au ▁sens ▁comm un .\"]\n"
     ]
    }
   ],
   "source": [
    "normalise(\"1. QVe cette propostion, qu'vn espace est vuidé, repugne au sens commun.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Quelques extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appliquer le modèle sur le texte entier (ou un plus grand nombre de phrases si vous ne voulez pas attendre).\n",
    "Le fichier entièrement normalisé est aussi disponible ici: `data/dev.norm.full.trg` si vous voulez juste l'évaluer et l'analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\r\n",
      "  beams_buf = indices_buf // vocab_size\r\n",
      "/Users/rbawden/miniconda3/envs/py37/lib/python3.7/site-packages/fairseq/sequence_generator.py:669: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\r\n",
      "  unfin_idx = idx // beam_size\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/dev.sp.src | fairseq-interactive models/ --source-lang src --target-lang trg --path models/lstm_norm.pt > data/dev.sp.norm.trg.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire une analyse qualitative de résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_frequent_diffs(alignments, show_n=10):\n",
    "    # TODO\n",
    "    return\n",
    "\n",
    "print_most_frequent_errors(alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire une analyse qualitative des différences entre un texte source et cible - faire cette analyse sur le jeu d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer une baseline par règles. Comme ressources supplémentaires, vous avez un lexique de mots en français contemporain et quelques fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a lexicon in the mlex format\n",
    "import gzip\n",
    "def read_lexicon(filename):\n",
    "    words = []\n",
    "    with gzip.open(filename, 'rt') as fp:\n",
    "        for line in fp:\n",
    "            words.append(line.split('\\t')[0])\n",
    "    return words\n",
    "\n",
    "\n",
    "def similarity_levenhstein(word1, word2):\n",
    "    dist, matrix, backpointers = levenshtein('@' + word1, '@' + word2)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def similarity_common_chars(word1, word2):\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = read_lexicon('data/lefff-3.4.mlex.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le lexique contient 549274 entrées.\n"
     ]
    }
   ],
   "source": [
    "print('Le lexique contient ' + str(len(lexicon)) + ' entrées.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_sent(sent, normalise_word_function):\n",
    "    norm_sent = []\n",
    "    for word in sent.split():\n",
    "        norm_sent.append(normalise_word_function(word))\n",
    "    return ' '.join(norm_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction qui renvoie simplement le même mot\n",
    "def return_word(word):\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"QVe cette propoſtion, qu'vn eſpace eſt vuidé\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalise_word_function = return_word\n",
    "normalise_sent(\"QVe cette propoſtion, qu'vn eſpace eſt vuidé\", normalise_word_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_long_s(word):\n",
    "    word = word.replace('ſ', 's')\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"QVe cette propostion, qu'vn espace est vuidé\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalise_word_function = replace_long_s\n",
    "normalise_sent(\"QVe cette propoſtion, qu'vn eſpace eſt vuidé\", normalise_word_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez créer une fonction qui contient plus de remplacement (comme `word.replace(before, after)`).\n",
    "\n",
    "Parfois, un remplacement peut être contextuel, donc si vous connaissez les expressions régulières vous pouvez les utiliser aussi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"QUe cette propostion, qu'un espace est vuidé\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def replace_regex(word):\n",
    "    word = word.replace('ſ', 's')\n",
    "    word = re.sub(\"([Qq])v\", r'\\1u', word)\n",
    "    word = re.sub(\"([Qq])V\", r'\\1U', word)\n",
    "    word = re.sub(\"([' ])vn(e?)\", r'\\1un\\2', word)\n",
    "    return word\n",
    "\n",
    "normalise_word_function = replace_regex\n",
    "normalise_sent(\"QVe cette propoſtion, qu'vn eſpace eſt vuidé\", normalise_word_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN8AweSe1ASxQbXHW5LKQ6B",
   "include_colab_link": true,
   "name": "Tutoriel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
