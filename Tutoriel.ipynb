{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rbawden/Tutoriel-Normalisation/blob/main/Tutoriel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorations sur la normalisation du fran√ßais moderne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup de l'environnement, t√©l√©chargement des fichiers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installer les paquets python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install fairseq@git+git://github.com/pytorch/fairseq.git@5a75b079bf8911a327940c28794608e003a9fa52 \n",
    "!pip install sentencepiece sacrebleu hydra-core omegaconf==2.0.5 gdown==4.2.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T√©l√©charger les donn√©es et les mod√®les depuis Google Drive et les structurer dans les dossiers `data/`, `models/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/drive/folders/1h-qSnPBPZFZQ_kqWIBMhkkFS-6C2b10H?usp=sharing -O data-models --folder\n",
    "!mv data-models/structure_files.sh ./; bash structure_files.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pr√©paration des donn√©es √† normaliser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions pour (i) lire le contenu d'un fichier ligne par ligne et (ii) les lire depuis un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lire un fichier ligne par ligne\n",
    "def read_file(filename):\n",
    "  list_sents = []\n",
    "  with open(filename) as fp:\n",
    "    for line in fp:\n",
    "      list_sents.append(line.strip())\n",
    "  return list_sents\n",
    "\n",
    "# √©crire une liste de phrases dans un fichier\n",
    "def write_file(list_sents, filename):\n",
    "    with open(filename, 'w') as fp:\n",
    "        for sent in list_sents:\n",
    "            fp.write(sent + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lire le contenu du texte source √† normaliser (`dev.src`) et le texte cible ('de r√©f√©rence'), c'est-√†-dire le texte correctement normalis√© (`dev.trg`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_src = read_file('data/dev.src')\n",
    "dev_trg = read_file('data/dev.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser le d√©but des textes sources (src) et cibles (trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print('src = ', dev_src[i])\n",
    "    print('trg = ', dev_trg[i])\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger le mod√®le de segmentation en sous-mots (`bpe_joint_1000.model`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece\n",
    "spm = sentencepiece.SentencePieceProcessor(model_file='data/bpe_joint_1000.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer le mod√®le de segmentation sur les donn√©es √† normaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_src_sp = spm.encode(dev_src, out_type=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√âcrire le texte pre-trait√© dans un fichier `dev.sp.src`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file([' '.join(phrase) for phrase in dev_src_sp], 'data/dev.sp.src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser le d√©but du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev_src_sp[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D√©finir une fonction pour d√©tokeniser une liste de phrases (pour plus tard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sp(list_sents):\n",
    "    return [''.join(sent).replace(' ', '').replace('‚ñÅ', ' ').strip() for sent in list_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser √† quoi ressemble le texte d√©tokenis√© (Spoiler: il devrait ressembler au texte de d√©part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_sp(dev_src_sp[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Appliquer le mod√®le de normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer le mod√®le de normalisation sur le d√©but des donn√©es pre-trait√©es (√ßa prend moins de temps pour tester que normaliser tout le texte)\n",
    "\n",
    "Il y aura un message \"UserWarning\", mais vous pouvez l'ignorer - ce n'est pas grave.\n",
    "\n",
    "Explications:\n",
    "- `head -n 10` affiche les 10 premi√®res phrases\n",
    "- ces 10 premi√®res lignes sont donn√© √† fairseq-interactive\n",
    "- le r√©sultat va dans `data/dev.sp.norm.trg.10.output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head -n 10 data/dev.sp.src | fairseq-interactive models/norm/ --source-lang src --target-lang trg --path models/norm/lstm_norm.pt > data/dev.sp.norm.trg.10.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sortie de fairseq-interactive donne quelque chose comme ceci:\n",
    "\n",
    "```\n",
    "S-0     ‚ñÅ1 .\n",
    "H-0     -0.00011481383990030736 ‚ñÅ1 .\n",
    "P-0     -0.0000 -0.0003 -0.0000\n",
    "S-1     ‚ñÅ1 . ‚ñÅQ V e ‚ñÅcette ‚ñÅprop ost ion , ‚ñÅqu ' vn ‚ñÅesp ace ‚ñÅest ‚ñÅv ui d √© , ‚ñÅre p u gne ‚ñÅau ‚ñÅsens ‚ñÅcomm un .\n",
    "H-1     -0.039981111884117126   ‚ñÅ1 . ‚ñÅQ U e ‚ñÅcette ‚ñÅprop ost ion , ‚ñÅqu ' un ‚ñÅesp ace ‚ñÅest ‚ñÅv ui d √© , ‚ñÅr√©p u gne ‚ñÅau ‚ñÅsens ‚ñÅcomm un .\n",
    "P-1     -0.0000 -0.0000 -0.0043 -0.0632 -0.0006 -0.0000 -0.0001 -0.9353 -0.0001 -0.0012 -0.0000 0.0000 -0.0001 -0.0078 -0.0070 -0.0000 -0.0022 -0.1168 -0.0001 -0.0000 -0.0000 -0.0389 -0.0157 -0.0053 -0.0000 -0.0000 -0.0001 -0.0000 -0.0004 -0.0000\n",
    "S-2     ‚ñÅ1 . ‚ñÅQ V e ‚ñÅtous ‚ñÅles ‚ñÅcor p s ‚ñÅont ‚ñÅre p u gn ance ‚ñÅ√† ‚ñÅse ‚ñÅse p are r ‚ñÅl ' vn ‚ñÅde ‚ñÅl ' autre , ‚ñÅ& ‚ñÅad m ettre ‚ñÅdu ‚ñÅv ui de ‚ñÅdans ‚ñÅleur ‚ñÅin ter u al le ;\n",
    "W-2     0.682   seconds\n",
    "H-2     -0.019450930878520012   ‚ñÅ1 . ‚ñÅQ U e ‚ñÅtous ‚ñÅles ‚ñÅcor p s ‚ñÅont ‚ñÅr√©p u gn ance ‚ñÅ√† ‚ñÅse ‚ñÅs √©p are r ‚ñÅl ' un ‚ñÅde ‚ñÅl ' autre , ‚ñÅet ‚ñÅad m ettre ‚ñÅdu ‚ñÅv ui de ‚ñÅdans ‚ñÅleur ‚ñÅin ter v √©s le ;\n",
    "D-2     -0.019450930878520012   ‚ñÅ1 . ‚ñÅQ U e ‚ñÅtous ‚ñÅles ‚ñÅcor p s ‚ñÅont ‚ñÅr√©p u gn ance ‚ñÅ√† ‚ñÅse ‚ñÅs √©p are r ‚ñÅl ' un ‚ñÅde ‚ñÅl ' autre , ‚ñÅet ‚ñÅad m ettre ‚ñÅdu ‚ñÅv ui de ‚ñÅdans ‚ñÅleur ‚ñÅin ter v √©s le ;\n",
    "P-2     -0.0000 -0.0001 -0.0040 -0.1684 -0.0004 -0.0000 -0.0000 -0.0000 -0.0007 -0.0000 -0.0001 -0.1220 -0.0063 -0.0002 -0.0137 -0.0000 -0.0000 -0.0002 -0.0001 -0.0248 -0.0022 -0.0003 -0.0000 -0.0000 -0.0000 -0.0000 -0.0000 -0.0000 -0.0002 -0.0001 -0.0000 -0.0000 -0.0000 -0.0000 -0.0383 -0.0173 -0.0006 -0.0000 -0.0000 -0.0000 -0.0066 -0.0016 -0.4856 -0.0007 -0.0002 -0.0000\n",
    "```\n",
    "\n",
    "Les informations int√©ressantes pour l'exemple `i`:\n",
    "\n",
    "- S-i: le texte source\n",
    "- H-i: le score de l'hypoth√®se et l'hypoth√®se du mod√®le (c'est-√†-dire la pr√©diction)\n",
    "- P-i: les scores de chaque sous-token produit par le mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour extraire l'hypoth√®se de ce fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hypothesis(filename):\n",
    "    outputs = []\n",
    "    with open(filename) as fp:\n",
    "        for line in fp:\n",
    "            # seulement les lignes qui commencet par H- (pour Hypoth√®se)\n",
    "            if 'H-' in line:\n",
    "                # prendre la 3√®me colonne (c'est-√†-dire l'indice 2)\n",
    "                outputs.append(line.strip().split('\\t')[2])\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraire les hypoth√®ses du fichier produit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_norm_10 = extract_hypothesis('data/dev.sp.norm.trg.10.output')\n",
    "dev_norm_10[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-traiter le texte avec la fonction pr√©cedemment d√©finie (d√©-segmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_norm_10_postproc = decode_sp(dev_norm_10)\n",
    "dev_norm_10_postproc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√âcrire le r√©sultat dans un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(dev_norm_10_postproc, 'data/dev.norm.10.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. √âvaluation du r√©sultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BLEU: le m√©trique d'√©valuation le plus fr√©quemment utilis√© en traduction automatique\n",
    "- ChrF: CharacterF score (like BLEU but based on n-grams of characters)\n",
    "- TER: translation edit rate\n",
    "\n",
    "Attention : puisque nous avons seulement normalis√© 10 phrases, il faut seulement comparer contre les 10 premi√®re phrases de r√©f√©rence. En r√©alit√©, il faudrait calculer ces scores sur un plus grand nombre de phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU, CHRF, TER\n",
    "bleu = BLEU()\n",
    "bleu.corpus_score(dev_norm_10_postproc, [dev_trg[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrf = CHRF()\n",
    "chrf.corpus_score(dev_norm_10_postproc, [dev_trg[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ter = TER()\n",
    "ter.corpus_score(dev_norm_10_postproc, [dev_trg[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une √©valuation plus adapt√©e : la pr√©cision au niveau de chaque mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d'abord cr√©er un fichier qui ne contient que les 10 premi√®re phrases du document cible\n",
    "!head -n 10 data/dev.trg > data/dev.10.trg\n",
    "align_dev_norm_10 = align.align('data/dev.10.trg', 'data/dev.norm.10.trg')\n",
    "\n",
    "print(align_dev_norm_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le r√©sultat de l'alignement est une liste de phrases, o√π chaque mot de la phrase est comme suit:\n",
    "\n",
    "- le mot tout seul s'il est pareil dans les deux textes (ex : `QUe`)\n",
    "- le mot du premier document et le mot du deuxi√®me document, s√©par√© par \">\" s'ils sont diff√©rents (ex : proposition>propostion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_diff = 0\n",
    "total = 0\n",
    "for sentence in align_dev_norm_10:\n",
    "    for word in sentence:\n",
    "        if '>' in word:\n",
    "            num_diff += 1\n",
    "        total += 1\n",
    "print('Accuracy = ' + str((total - num_diff)/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tester le mod√®le de d√©normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparer les donn√©es normalis√©es qui vont √™tre d√©normalis√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_trg_sp = spm.encode(dev_trg, out_type=str) # tokenise the sentence into subtokens\n",
    "decade_token = '‚ñÅ<decade=162> ' # special token indicating the decade\n",
    "write_file([' '.join([decade_token] + phrase) for phrase in dev_trg_sp], 'data/dev.sp.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normaliser le texte\n",
    "\n",
    "(10 premi√®res phrases seulement. Vous pouvez faire plus de phrases en modifiant le 10. Vous pouvez tout normaliser en changeant `head -n 10` en `cat`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 10 data/dev.sp.trg | fairseq-interactive models/denorm --source-lang trg --target-lang src --path models/denorm/lstm_denorm.pt > data/dev.sp.denorm.src.10.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-traiter la sortie du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_denorm_10 = extract_hypothesis('data/dev.sp.denorm.src.10.output')\n",
    "dev_denorm_10_postproc = decode_sp(dev_denorm_10)\n",
    "write_file(dev_denorm_10_postproc, 'data/dev.sp.denorm.10.src')\n",
    "dev_denorm_10_postproc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a pas mal d'√©tapes, donc pour faciliter le traitement, voici une fonction qui prend en entr√©e une liste de phrases et qui fait tout :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalise(sents, decade):\n",
    "    assert int(decade) >=1600 and int(decade) < 1700, 'Your decade must be between 1600 and 1690'\n",
    "    # generate temporary file\n",
    "    filetmp = 'data/tmp_denorm.sp.trg.tmp'\n",
    "    # preprocessing\n",
    "    input_sp = spm.encode(sents, out_type=str)\n",
    "    # add decade token to each sentence\n",
    "    decade_token = '‚ñÅ<decade=' + str(decade)[:3] + '>'\n",
    "    input_sp_sents = [' '.join([decade_token] + sent) for sent in input_sp]\n",
    "    write_file(input_sp_sents, filetmp)\n",
    "    #print(\"preprocessed = \", input_sp_sents)\n",
    "    # denormalisation\n",
    "    !cat data/tmp_denorm.sp.trg.tmp | fairseq-interactive models/denorm --source-lang trg --target-lang src --path models/denorm/lstm_denorm.pt > data/tmp_denorm.sp.trg.output 2> /tmp/dev\n",
    "    # postprocessing\n",
    "    outputs = extract_hypothesis('data/tmp_denorm.sp.trg.output')\n",
    "    outputs_postproc = decode_sp(outputs)\n",
    "    return outputs_postproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et on peut la tester comme suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(denormalise([\"Je ne savais pas qu'il faisait si beau.\"], 1640))\n",
    "print(denormalise([\"Je ne savais pas qu'il faisait si beau.\"], 1690))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voici une fonction similaire pour la normalisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(sents):\n",
    "    # generate temporary file\n",
    "    filetmp = 'data/tmp_norm.sp.src.tmp'\n",
    "    # preprocessing\n",
    "    input_sp = spm.encode(sents, out_type=str)\n",
    "    # add decade token to each sentence\n",
    "    input_sp_sents = [' '.join(sent) for sent in input_sp]\n",
    "    write_file(input_sp_sents, filetmp)\n",
    "    #print(\"preprocessed = \", input_sp_sents)\n",
    "    # denormalisation\n",
    "    !cat data/tmp_norm.sp.src.tmp | fairseq-interactive models/norm --source-lang src --target-lang trg --path models/norm/lstm_norm.pt > data/tmp_norm.sp.src.output 2> /tmp/dev\n",
    "    # postprocessing\n",
    "    outputs = extract_hypothesis('data/tmp_norm.sp.src.output')\n",
    "    outputs_postproc = decode_sp(outputs)\n",
    "    return outputs_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise([\"1. QVe cette propostion, qu'vn espace est vuid√©, repugne au sens commun.\",\n",
    "          \"Affectoit un m√©pris qui marquoit ≈øon e≈øtime,\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Quelques extensions (y compris du code √† faire üë©üèª‚ÄçüíªüßëüèΩ‚Äçüíª)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appliquer le mod√®le sur le texte entier\n",
    "\n",
    "Attention : normaliser le fichier entier prend environ 6 minutes en utilisant le GPU\n",
    "\n",
    "Si vous voulez juste l'√©valuer et l'analyser (sans refaire la normalisation), le fichier enti√®rement normalis√© est disponible ici: `data/dev.norm.full.trg` \n",
    "\n",
    "Ou vous pouvez normaliser une partie du fichier seulement (comme avant mais avec plus de phrases que 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_norm = normalise(dev_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(dev_norm, 'data/dev.norm.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Refaire l'√©valuation sur le texte entier (pas juste sur les 10 premi√®res phrases) : BLEU, ChrF, TER et exactitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez refaire la normalisation pour le jeu de test maintenant (il se trouve dans `data/test.src`) et l'√©valuer/l'analyser\n",
    "\n",
    "La normalisation compl√®te se trouve dans `data/test.norm.full.trg` si vous ne voulez pas attendre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_src = read_file('data/test.src')\n",
    "test_norm = normalise(test_src)\n",
    "#test_norm = read_file('data/test.norm.full.trg') # pour utiliser le texte d√©j√† normalis√©, d√©commenter cette ligner et commenter la ligne pr√©c√©dente\n",
    "write_file(test_norm, 'data/test.norm.trg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez aussi faire la m√™me √©valuation sur le texte source pour voir quels seraient les scores si on ne changeait rien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire une analyse qualitative de r√©sultats (sur le dev et/ou le test)\n",
    "\n",
    "Compl√©tez cette fonction pour afficher les diff√©rences les plus fr√©quentes.\n",
    "\n",
    "(Le calcul des alignements est lent, donc vous pouvez tester avec moins de phrases aussi, surtout lorsque vous tester simplement votre fonction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 100 data/dev.trg > data/dev.100.trg\n",
    "!head -n 100 data/dev.norm.full.trg > data/dev.norm.100.trg\n",
    "alignments_dev = align.align('data/dev.100.trg', 'data/dev.norm.100.trg')\n",
    "#alignments_dev = align.align('data/dev.trg', 'data/dev.norm.full.trg') # d√©commenter pour traiter le jeu de dev en entier\n",
    "\n",
    "\n",
    "# get alignments\n",
    "def print_most_frequent_diffs(alignments, show_n=10):\n",
    "    # TODO\n",
    "    return\n",
    "\n",
    "print_most_frequent_diffs(alignments_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire une analyse qualitative des diff√©rences entre un texte source et cible pour visualiser les corresondences de normalisation.\n",
    "\n",
    "Id√©alement ceci se fait sur le jeu d'entra√Ænement (`data/train.src` et `data/train.trg`), mais √ßa risque de prendre trop de temps pour ce TP, donc prenez une sous-partie des exemples (en utilisant `head` comme avant) !\n",
    "\n",
    "- lire les deux fichiers\n",
    "- appliquer l'alignement\n",
    "- utiliser la fonction `print_most_frequent_diffs` (pr√©c√©demment utilis√©e pour comparer la pr√©diction contre la r√©f√©rence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cr√©er un mod√®le baseline par r√®gles. Comme ressources suppl√©mentaires, vous avez un lexique de mots en fran√ßais contemporain et quelques fonctions\n",
    "\n",
    "Id√©es possibles:\n",
    "\n",
    "- remplacer les caract√®res qui changent syst√©matiquement en utilisant la fonction `replace(avant, apr√®s)` : `word = word.replace('≈ø', 's')`\n",
    "- remplacer les caract√®res en utilisant les expressions r√©guli√®res (si vous les connaissez) : `word = word.replace('vn(e?)', r'un\\1')`\n",
    "- parcourir les mots de la phrase et si le mot n'appara√Æt pas dans le lexique, trouver le mot du lexique qui est le plus similaire. Quelques id√©es de fonctions de similarit√©:\n",
    "  - la distance de levenshtein (la fonction est donn√©e ci-dessous)\n",
    "  - une fonction plus simple qui compare le nombre de caract√®res en commun entre les deux mots (√† faire)\n",
    "  - il serait peut-√™tre sage de normaliser cette derni√®re similarit√© par la longueur des mots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a lexicon in the mlex format\n",
    "import gzip\n",
    "def read_lexicon(filename):\n",
    "    words = []\n",
    "    with gzip.open(filename, 'rt') as fp:\n",
    "        for line in fp:\n",
    "            words.append(line.split('\\t')[0])\n",
    "    return words\n",
    "\n",
    "# calculate the levenshtein distance\n",
    "def similarity_levenshtein(word1, word2):\n",
    "    dist, matrix, backpointers = levenshtein('@' + word1, '@' + word2)\n",
    "    return dist\n",
    "\n",
    "# calculate the number of common characters between the two words\n",
    "def similarity_common_chars(word1, word2):\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = read_lexicon('data/lefff-3.4.mlex.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Le lexique contient ' + str(len(lexicon)) + ' entr√©es.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that normalises a sentence given a function that normalises a word\n",
    "import utils\n",
    "from importlib import reload\n",
    "reload(utils)\n",
    "def normalise_sent(sent, normalise_word_function):\n",
    "    norm_sent = []\n",
    "    # go through the sentence word by word (the tokenisation function is very approximate here!)\n",
    "    for word in utils.basic_tokenise(sent).split():\n",
    "        norm_sent.append(normalise_word_function(word))\n",
    "    return utils.detokenise(' '.join(norm_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns the word itself\n",
    "def return_word(word):\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# illustration of how this could work (using just the function that returns the original word)\n",
    "normalise_word_function = return_word\n",
    "normalise_sent(\"QVe cette propo≈øtion, qu'vn e≈øpace e≈øt vuid√©\", normalise_word_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that replaces the long s\n",
    "def replace_long_s(word):\n",
    "    word = word.replace('≈ø', 's')\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on peut tester avec une autre petite fonction qui ne fait que remplacer les ≈ø par s :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise_word_function = replace_long_s\n",
    "normalise_sent(\"QVe cette propo≈øtion, qu'vn e≈øpace e≈øt vuid√©\", normalise_word_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez cr√©er une fonction qui contient plus de remplacements (comme `word.replace(before, after)`).\n",
    "\n",
    "Parfois, un remplacement peut √™tre contextuel, donc si vous connaissez les expressions r√©guli√®res vous pouvez les utiliser aussi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def replace_regex(word):\n",
    "    word = word.replace('≈ø', 's')\n",
    "    word = re.sub(\"([Qq])v\", r'\\1u', word)\n",
    "    word = re.sub(\"([Qq])V\", r'\\1U', word)\n",
    "    word = re.sub(\"('?)vn(e?)\", r'\\1un\\2', word)\n",
    "    return word\n",
    "\n",
    "normalise_word_function = replace_regex\n",
    "normalise_sent(\"QVe cette propo≈øtion, qu'vn e≈øpace e≈øt vuid√©\", normalise_word_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entra√Æner un mod√®le de segmentation en sous-mots en avec le toolkit sentencepiece\n",
    "\n",
    "Ce sera un mod√®le joint - c'est-√†-dire qu'il est entra√Æn√© pour segmenter la langue source et cible et √ßa permet de faire des sous-mots qui peuvent √™tre partag√©s pour les deux langues. C'est surtout bien pour les langues proches lexicalement.\n",
    "\n",
    "La taille du vocabulaire ici est de 2000, mais ceci peut √™tre chang√©. La taille du vocabulaire d√©termine combien on d√©coup√© le texte. Plus le vocabulaire est petit, plus le texte sera d√©coup√©, plus le vocabulaire est grand, moins le texte sera d√©coup√© (√ßa ressemblera plus √† un d√©coupage sur les blancs). Vous pouvez tester avec des tailles de vocabulaires diff√©rents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the source and target sides of the training set to train a joint model (encourages lexical sharing between the units)\n",
    "!cat data/train.src data/train.trg > data/all_train.src-trg\n",
    "sentencepiece.SentencePieceTrainer.train(input='data/all_train.src-trg', \n",
    "                               model_prefix='data/bpe_joint_2000', \n",
    "                               vocab_size=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lire les trois jeux (train, dev, test) et appliquer les pr√©-traitements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src = read_file('data/train.src')\n",
    "train_trg = read_file('data/train.trg')\n",
    "dev_src = read_file('data/dev.src')\n",
    "dev_trg = read_file('data/dev.trg')\n",
    "test_src = read_file('data/test.src')\n",
    "test_trg = read_file('data/test.trg')\n",
    "\n",
    "# load newly trained sentencepiece models\n",
    "spm = sentencepiece.SentencePieceProcessor(model_file='data/bpe_joint_2000.model')\n",
    "\n",
    "# apply sentencepiece to each of the datasets\n",
    "train_src_sp = spm.encode(train_src, out_type=str)\n",
    "train_trg_sp = spm.encode(train_trg, out_type=str)\n",
    "dev_src_sp = spm.encode(dev_src, out_type=str)\n",
    "dev_trg_sp = spm.encode(dev_trg, out_type=str)\n",
    "test_src_sp = spm.encode(test_src, out_type=str)\n",
    "test_trg_sp = spm.encode(test_trg, out_type=str)\n",
    "\n",
    "# print out lengths (src and trg must be the same length for each type of set)\n",
    "print(len(dev_src_sp), len(train_trg_sp))\n",
    "print(len(dev_src_sp), len(dev_trg_sp))\n",
    "print(len(test_src_sp), len(test_trg_sp))\n",
    "\n",
    "# write them to file\n",
    "write_file([' '.join(sent) for sent in train_src_sp], 'data/train.sp2000.src')\n",
    "write_file([' '.join(sent) for sent in train_trg_sp], 'data/train.sp2000.trg')\n",
    "write_file([' '.join(sent) for sent in dev_src_sp], 'data/dev.sp2000.src')\n",
    "write_file([' '.join(sent) for sent in dev_trg_sp], 'data/dev.sp2000.trg')\n",
    "write_file([' '.join(sent) for sent in test_src_sp], 'data/test.sp2000.src')\n",
    "write_file([' '.join(sent) for sent in test_trg_sp], 'data/test.sp2000.trg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entra√Æner un mod√®le r√©current (de type LSTM) avec fairseq "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut d'abord binariser les donn√©es pour rendre l'utilisation de donn√©es plus efficace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-preprocess --destdir data/data_norm_bin_2000/ \\\n",
    "                    -s trg -t src \\\n",
    "                    --trainpref data/train.sp2000 \\\n",
    "                    --validpref data/dev.sp2000 \\\n",
    "                    --testpref data/test.sp2000 \\\n",
    "                    --joined-dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on peut appeler fairseq-train avec les param√®tres souhait√©s\n",
    "\n",
    "- Le mod√®le entra√Æn√© se trouvera dans `models/new_norm_lstm/` (l'option `--save-dir`).\n",
    "- En pratique, le mod√®le sera sauvegard√© plusieurs fois pendant l'entra√Ænement (des checkpoints). La fr√©quence de sauvegarde peut √™tre choisi avec l'option `--save-interval` (tous les `n` epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty model folder to store the model in\n",
    "!mkdir models/new_norm_lstm\n",
    "\n",
    "# call fairseq-train\n",
    "!fairseq-train \\\n",
    "        data/data_norm_bin_2000 \\\n",
    "        --save-dir models/new_norm_lstm \\\n",
    "        --save-interval 1 --patience 12 \\\n",
    "        --arch lstm \\\n",
    "        --encoder-layers 3 --decoder-layers 3 \\\n",
    "        --encoder-embed-dim 384 --decoder-embed-dim 384 --decoder-out-embed-dim 384 \\\n",
    "        --encoder-hidden-size 768 --encoder-bidirectional --decoder-hidden-size 768 \\\n",
    "        --dropout 0.3 \\\n",
    "        --criterion cross_entropy --optimizer adam --adam-betas '(0.9, 0.98)' \\\n",
    "        --lr 0.0001 --lr-scheduler inverse_sqrt \\\n",
    "        --warmup-updates 4000 \\\n",
    "        --share-all-embeddings \\\n",
    "        --max-tokens 3000 \\\n",
    "        --batch-size-valid 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entra√Æner un mod√®le de type transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty model folder to store the model in\n",
    "!mkdir models/new_norm_lstm\n",
    "\n",
    "# call fairseq-train\n",
    "!fairseq-train \\\n",
    "        data/data_norm_bin_2000 \\\n",
    "        --save-dir models/new_norm_transformer \\\n",
    "        --save-interval 1 --patience 25 \\\n",
    "        --arch transformer \\\n",
    "        --encoder-layers 2 --decoder-layers 4 --encoder-attention-heads 4 \\\n",
    "        --encoder-embed-dim 256 --encoder-ffn-embed-dim 1024 --dropout 0.3 \\\n",
    "        --criterion cross_entropy --optimizer adam --adam-betas '(0.9, 0.98)' \\\n",
    "        --lr 0.001 --lr-scheduler inverse_sqrt \\\n",
    "        --warmup-updates 4000 \\\n",
    "        --max-tokens 3000 --max-tokens 3000 \\\n",
    "        --share-all-embeddings --batch-size-valid 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN8AweSe1ASxQbXHW5LKQ6B",
   "include_colab_link": true,
   "name": "Tutoriel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
